{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f0a206",
   "metadata": {},
   "source": [
    "# ç—…åºŠå§¿å‹¢ç›£æ¸¬ - è³‡æ–™æº–å‚™èˆ‡å°é½Šï¼ˆVersion 4 - ä¿®æ­£ç´¯ç©èª¤å·®ï¼‰\n",
    "\n",
    "**å°ˆæ¡ˆ**: ç†±æˆåƒè¶…è§£æåº¦ + å§¿å‹¢è¾¨è­˜  \n",
    "**ä½œè€…**: rochi190  \n",
    "**æ—¥æœŸ**: 2025-11-06  \n",
    "**ç‰ˆæœ¬**: v4 - ä¿®æ­£ Thermal æ™‚é–“æˆ³ç´¯ç©èª¤å·®å•é¡Œ\n",
    "\n",
    "## ä¿®æ­£é‡é»\n",
    "- âœ… **ä½¿ç”¨å…¨åŸŸå¹€è¨ˆæ•¸å™¨**ï¼Œé¿å…ç§’ç´šåˆ†çµ„çš„ç´¯ç©èª¤å·®\n",
    "- âœ… **å¾®ç§’è¨ˆç®—ä¿®æ­£**ï¼šç›´æ¥è¨ˆç®—å¾®ç§’è€Œéæ¯«ç§’*1000\n",
    "- âœ… **æ™‚é–“æˆ³ä¸å†è¢«ä¿®æ”¹**ï¼šä¿æŒåŸå§‹é…å°æ™‚é–“çš„ä¸€è‡´æ€§\n",
    "- âœ… **ç°¡åŒ–é…å°é‚è¼¯**ï¼šç›´æ¥æŒ‰æ™‚é–“æˆ³é…å°ï¼Œç§»é™¤è¤‡é›œçš„ burst/dropout è™•ç†\n",
    "\n",
    "## åŠŸèƒ½\n",
    "1. è®€å– output.txt å–å¾—ç›¸æ©Ÿé–‹å§‹æ™‚é–“\n",
    "2. è¼‰å…¥ç†±æˆåƒè³‡æ–™ï¼ˆå…¨åŸŸå¹€è¨ˆæ•¸å™¨ï¼Œç„¡ç´¯ç©èª¤å·®ï¼‰\n",
    "3. åˆ†æ RGB å½±ç‰‡è³‡è¨Š\n",
    "4. **ç›´æ¥æ™‚é–“æˆ³é…å°**ï¼ˆç°¡å–®ä¸”æº–ç¢ºï¼‰\n",
    "5. ç¿»è½‰æª¢æ¸¬èˆ‡ä¿®å¾©\n",
    "6. åŒ¯å‡º RGB åœ–ç‰‡ä¾› LabelMe æ¨™è¨»\n",
    "7. å„²å­˜å°é½Šå¾Œçš„ Thermal è³‡æ–™\n",
    "\n",
    "## è¼¸å‡º\n",
    "- `output/labelme_project/` - LabelMe æ¨™è¨»å°ˆæ¡ˆ\n",
    "- `output/aligned_dataset/` - å°é½Šå¾Œçš„è¨“ç·´è³‡æ–™\n",
    "- `output/pairing_analysis/` - é…å°åˆ†æçµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6fd2d",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: ç’°å¢ƒè¨­å®šèˆ‡å¥—ä»¶åŒ¯å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3118ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ç—…åºŠå§¿å‹¢ç›£æ¸¬ç³»çµ± - è³‡æ–™æº–å‚™æ¨¡çµ„ v4ï¼ˆä¿®æ­£ç´¯ç©èª¤å·®ï¼‰\n",
      "======================================================================\n",
      "åŸ·è¡Œæ™‚é–“: 2025-11-08 02:25:11\n",
      "ä½¿ç”¨è€…: rochi190\n",
      "Python ç‰ˆæœ¬: 3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]\n",
      "NumPy ç‰ˆæœ¬: 2.3.4\n",
      "OpenCV ç‰ˆæœ¬: 4.10.0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯ï¼ˆé©ç”¨æ–¼ SSH ç’°å¢ƒï¼‰\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib è¨­å®š\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Seaborn æ¨£å¼\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ç—…åºŠå§¿å‹¢ç›£æ¸¬ç³»çµ± - è³‡æ–™æº–å‚™æ¨¡çµ„ v4ï¼ˆä¿®æ­£ç´¯ç©èª¤å·®ï¼‰\")\n",
    "print(\"=\"*70)\n",
    "print(f\"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ä½¿ç”¨è€…: rochi190\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\n",
    "print(f\"OpenCV ç‰ˆæœ¬: {cv2.__version__}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e7d8e",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: è·¯å¾‘èˆ‡åƒæ•¸é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffbbeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ è·¯å¾‘æª¢æŸ¥:\n",
      "  Thermal ç›®éŒ„: âœ“ /home/gary/claude4.5/data/thermal\n",
      "  Camera ç›®éŒ„: âœ“ /home/gary/claude4.5/data/camera\n",
      "  output.txt: âœ“ /home/gary/claude4.5/data/camera/output.txt\n",
      "  AVI æª”æ¡ˆ: âœ“ /home/gary/claude4.5/data/camera/output.avi\n",
      "\n",
      "âš™ï¸ é…å°åƒæ•¸:\n",
      "  ç›®æ¨™ FPS: 8\n",
      "  å¹€é–“éš”: 125.0ms\n",
      "\n",
      "ğŸ”„ ç¿»è½‰è¨­å®š:\n",
      "  ç¿»è½‰ Thermal: True\n",
      "  ç¿»è½‰ RGB: False\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# è·¯å¾‘é…ç½®\n",
    "# ========================================\n",
    "NUM_WORKERS = max(1, mp.cpu_count() - 1)\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "THERMAL_DIR = DATA_DIR / 'thermal'\n",
    "CAMERA_DIR = DATA_DIR / 'camera'\n",
    "OUTPUT_TXT = CAMERA_DIR / 'output.txt'\n",
    "AVI_FILE = CAMERA_DIR / 'output.avi'\n",
    "\n",
    "# è¼¸å‡ºç›®éŒ„\n",
    "OUTPUT_DIR = BASE_DIR / 'output_v7'\n",
    "PAIRING_DIR = OUTPUT_DIR / 'pairing_analysis'\n",
    "LABELME_DIR = OUTPUT_DIR / 'labelme_project'\n",
    "ALIGNED_DIR = OUTPUT_DIR / 'aligned_dataset'\n",
    "DIAGNOSTIC_DIR = OUTPUT_DIR / 'diagnostics'\n",
    "\n",
    "for directory in [PAIRING_DIR, LABELME_DIR, ALIGNED_DIR, DIAGNOSTIC_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# ç†±æˆåƒåƒæ•¸\n",
    "# ========================================\n",
    "THERMAL_RESOLUTION = (32, 24)  # (å¯¬åº¦, é«˜åº¦)\n",
    "THERMAL_WIDTH, THERMAL_HEIGHT = THERMAL_RESOLUTION\n",
    "\n",
    "# ========================================\n",
    "# é…å°åƒæ•¸\n",
    "# ========================================\n",
    "TARGET_FPS = 8  # ç›®æ¨™ FPS\n",
    "FRAME_INTERVAL_MS = 1000 / TARGET_FPS  # 125ms\n",
    "\n",
    "# ç¿»è½‰è¨­å®šï¼ˆåŸ·è¡Œ Step 7 å¾Œèª¿æ•´ï¼‰\n",
    "FLIP_THERMAL = True\n",
    "FLIP_RGB = False\n",
    "\n",
    "# ========================================\n",
    "# é¡¯ç¤ºé…ç½®\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“ è·¯å¾‘æª¢æŸ¥:\")\n",
    "print(f\"  Thermal ç›®éŒ„: {'âœ“' if THERMAL_DIR.exists() else 'âœ—'} {THERMAL_DIR}\")\n",
    "print(f\"  Camera ç›®éŒ„: {'âœ“' if CAMERA_DIR.exists() else 'âœ—'} {CAMERA_DIR}\")\n",
    "print(f\"  output.txt: {'âœ“' if OUTPUT_TXT.exists() else 'âœ—'} {OUTPUT_TXT}\")\n",
    "print(f\"  AVI æª”æ¡ˆ: {'âœ“' if AVI_FILE.exists() else 'âœ—'} {AVI_FILE}\")\n",
    "\n",
    "print(f\"\\nâš™ï¸ é…å°åƒæ•¸:\")\n",
    "print(f\"  ç›®æ¨™ FPS: {TARGET_FPS}\")\n",
    "print(f\"  å¹€é–“éš”: {FRAME_INTERVAL_MS:.1f}ms\")\n",
    "\n",
    "print(f\"\\nğŸ”„ ç¿»è½‰è¨­å®š:\")\n",
    "print(f\"  ç¿»è½‰ Thermal: {FLIP_THERMAL}\")\n",
    "print(f\"  ç¿»è½‰ RGB: {FLIP_RGB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d445c",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: è§£æ output.txtï¼ˆç›¸æ©Ÿé–‹å§‹æ™‚é–“ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0deb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "è§£æ output.txt\n",
      "======================================================================\n",
      "æª”æ¡ˆå¤§å°: 898 bytes\n",
      "\n",
      "å®Œæ•´å…§å®¹:\n",
      "viedo_start_2020-09-24 13:09:30\n",
      "lay_mid_2020-09-24 13:11:08 \n",
      "end_time_2020-09-24 13:11:43 \n",
      "lay_right_2020-09-24 13:12:02 \n",
      "end_time_2020-09-24 13:12:39 \n",
      "lay_left_2020-09-24 13:12:58 \n",
      "end_time_2020-09-24 13:13:36 \n",
      "bed_2020-09-24 13:13:53 \n",
      "end_time_2020-09-24 13:14:32 \n",
      "sit_right_2020-09-24 13:14:40 \n",
      "end_time_2020-09-24 13:15:22 \n",
      "sit_left_2020-09-24 13:15:27 \n",
      "end_time_2020-09-24 13:16:04 \n",
      "Falldown_2020-09-24 13:16:38 \n",
      "end_time_2020-09-24 13:16:43 \n",
      "Falldown_2020-09-24 13:16:57 \n",
      "end_time_2020-09-24 13:17:01 \n",
      "Falldown_2020-09-24 13:17:38 \n",
      "end_time_2020-09-24 13:17:42 \n",
      "Falldown_2020-09-24 13:17:53 \n",
      "end_time_2020-09-24 13:17:58 \n",
      "Falldown_2020-09-24 13:18:09 \n",
      "end_time_2020-09-24 13:18:12 \n",
      "Falldown_2020-09-24 13:18:34 \n",
      "end_time_2020-09-24 13:18:38 \n",
      "Falldown_2020-09-24 13:19:06 \n",
      "end_time_2020-09-24 13:19:08 \n",
      "Falldown_2020-09-24 13:20:07 \n",
      "Falldown_2020-09-24 13:20:09 \n",
      "Falldown_2020-09-24 13:20:18 \n",
      "\n",
      "======================================================================\n",
      "\n",
      "âœ… æ‰¾åˆ°ç›¸æ©Ÿé–‹å§‹æ™‚é–“: 2020-09-24 13:09:30\n",
      "\n",
      "ğŸ“Œ ç›¸æ©Ÿé–‹å§‹æ™‚é–“: 2020-09-24 13:09:30\n"
     ]
    }
   ],
   "source": [
    "def parse_output_txt(txt_path: Path) -> Optional[datetime]:\n",
    "    \"\"\"\n",
    "    è§£æ output.txt å–å¾—ç›¸æ©Ÿé–‹å§‹æ™‚é–“\n",
    "    \"\"\"\n",
    "    if not txt_path.exists():\n",
    "        print(f\"âŒ {txt_path} ä¸å­˜åœ¨\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except:\n",
    "        with open(txt_path, 'r', encoding='big5') as f:\n",
    "            content = f.read()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"è§£æ output.txt\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"æª”æ¡ˆå¤§å°: {len(content)} bytes\")\n",
    "    print(f\"\\nå®Œæ•´å…§å®¹:\\n{content}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # æ™‚é–“æ ¼å¼æ¨¡å¼\n",
    "    patterns = [\n",
    "        (r'(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2})', '%Y-%m-%d %H:%M:%S'),\n",
    "        (r'(\\d{4}/\\d{2}/\\d{2}\\s+\\d{2}:\\d{2}:\\d{2})', '%Y/%m/%d %H:%M:%S'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, fmt in patterns:\n",
    "        match = re.search(pattern, content)\n",
    "        if match:\n",
    "            try:\n",
    "                camera_start = datetime.strptime(match.group(1), fmt)\n",
    "                print(f\"\\nâœ… æ‰¾åˆ°ç›¸æ©Ÿé–‹å§‹æ™‚é–“: {camera_start}\")\n",
    "                return camera_start\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nâŒ ç„¡æ³•è§£ææ™‚é–“\")\n",
    "    return None\n",
    "\n",
    "# åŸ·è¡Œè§£æ\n",
    "camera_start_time = parse_output_txt(OUTPUT_TXT)\n",
    "\n",
    "if camera_start_time is None:\n",
    "    raise RuntimeError(\"âŒ ç„¡æ³•è§£æ output.txtï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ ç›¸æ©Ÿé–‹å§‹æ™‚é–“: {camera_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e342",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: è¼‰å…¥ç†±æˆåƒè³‡æ–™ï¼ˆå…¨åŸŸè¨ˆæ•¸å™¨ç‰ˆæœ¬ - ä¿®æ­£ç´¯ç©èª¤å·®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df1edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "è¼‰å…¥ç†±æˆåƒè³‡æ–™ï¼ˆå…¨åŸŸè¨ˆæ•¸å™¨ç‰ˆæœ¬ï¼‰\n",
      "======================================================================\n",
      "æ‰¾åˆ° 5 å€‹ log æª”æ¡ˆ\n",
      "ğŸ”§ ä½¿ç”¨å…¨åŸŸå¹€è¨ˆæ•¸å™¨ï¼Œæ¯å¹€é–“éš” 125.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è¼‰å…¥ Thermal: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… è¼‰å…¥å®Œæˆ\n",
      "  ç¸½å¹€æ•¸: 5,318\n",
      "  ç¬¬ä¸€å¹€: 2020-09-24 13:09:30\n",
      "  æœ€å¾Œå¹€: 2020-09-24 13:20:34.625000\n",
      "  æ™‚é•·: 664.62 ç§’\n",
      "  å¹³å‡ FPS: 8.00\n",
      "\n",
      "  æ™‚é–“é–“éš”çµ±è¨ˆï¼ˆå‰ 100 å¹€ï¼‰:\n",
      "    å¹³å‡: 125.0ms\n",
      "    æ¨™æº–å·®: 0.0ms\n",
      "    æœ€å°å€¼: 125.0ms\n",
      "    æœ€å¤§å€¼: 125.0ms\n",
      "    é æœŸ: 125.0ms\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_thermal_data_with_global_counter(log_files: List[Path]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    è¼‰å…¥ç†±æˆåƒè³‡æ–™ï¼ˆä½¿ç”¨å…¨åŸŸå¹€è¨ˆæ•¸å™¨ï¼Œé¿å…ç´¯ç©èª¤å·®ï¼‰\n",
    "    \n",
    "    ä¿®æ­£é‡é»ï¼š\n",
    "    1. ä½¿ç”¨å…¨åŸŸå¹€è¨ˆæ•¸å™¨ï¼Œä¸ä¾è³´ç§’ç´šåˆ†çµ„\n",
    "    2. å¾ç¬¬ä¸€å¹€é–‹å§‹ï¼Œæ¯å¹€é–“éš”å›ºå®š 125ms\n",
    "    3. é¿å… burst/dropout å°è‡´çš„æ™‚é–“è·³èº\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"è¼‰å…¥ç†±æˆåƒè³‡æ–™ï¼ˆå…¨åŸŸè¨ˆæ•¸å™¨ç‰ˆæœ¬ï¼‰\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"æ‰¾åˆ° {len(log_files)} å€‹ log æª”æ¡ˆ\")\n",
    "    print(f\"ğŸ”§ ä½¿ç”¨å…¨åŸŸå¹€è¨ˆæ•¸å™¨ï¼Œæ¯å¹€é–“éš” {FRAME_INTERVAL_MS:.1f}ms\")\n",
    "    \n",
    "    all_data = []\n",
    "    global_frame_count = 0\n",
    "    first_timestamp = None\n",
    "    \n",
    "    for log_file in tqdm(log_files, desc=\"è¼‰å…¥ Thermal\"):\n",
    "        try:\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_dict = json.loads(line)\n",
    "                        time_parts = data_dict.get('time', [])\n",
    "                        \n",
    "                        if len(time_parts) < 6:\n",
    "                            continue\n",
    "                        \n",
    "                        year, month, day, hour, minute, second = time_parts[:6]\n",
    "                        original_timestamp = datetime(year, month, day, hour, minute, second)\n",
    "                        \n",
    "                        # è¨˜éŒ„ç¬¬ä¸€å¹€çš„æ™‚é–“æˆ³ä½œç‚ºåŸºæº–\n",
    "                        if first_timestamp is None:\n",
    "                            first_timestamp = original_timestamp\n",
    "                        \n",
    "                        # ğŸ”§ ä½¿ç”¨å…¨åŸŸè¨ˆæ•¸å™¨è¨ˆç®—ç²¾ç¢ºæ™‚é–“æˆ³\n",
    "                        offset_ms = global_frame_count * FRAME_INTERVAL_MS\n",
    "                        timestamp = first_timestamp + timedelta(milliseconds=offset_ms)\n",
    "                        \n",
    "                        message = data_dict.get('message', [])\n",
    "                        if len(message) != THERMAL_WIDTH * THERMAL_HEIGHT:\n",
    "                            continue\n",
    "                        \n",
    "                        thermal_image = np.array(message, dtype=np.uint8).reshape(\n",
    "                            THERMAL_HEIGHT, THERMAL_WIDTH\n",
    "                        )\n",
    "                        \n",
    "                        all_data.append({\n",
    "                            'timestamp': timestamp,\n",
    "                            'image': thermal_image,\n",
    "                            'frame_number': global_frame_count,\n",
    "                            'original_timestamp': original_timestamp\n",
    "                        })\n",
    "                        \n",
    "                        global_frame_count += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¼‰å…¥å¤±æ•— {log_file.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nâœ… è¼‰å…¥å®Œæˆ\")\n",
    "    print(f\"  ç¸½å¹€æ•¸: {len(all_data):,}\")\n",
    "    \n",
    "    if all_data:\n",
    "        thermal_start = all_data[0]['timestamp']\n",
    "        thermal_end = all_data[-1]['timestamp']\n",
    "        duration = (thermal_end - thermal_start).total_seconds()\n",
    "        \n",
    "        print(f\"  ç¬¬ä¸€å¹€: {thermal_start}\")\n",
    "        print(f\"  æœ€å¾Œå¹€: {thermal_end}\")\n",
    "        print(f\"  æ™‚é•·: {duration:.2f} ç§’\")\n",
    "        print(f\"  å¹³å‡ FPS: {len(all_data) / duration:.2f}\")\n",
    "        \n",
    "        # é©—è­‰æ™‚é–“é–“éš”\n",
    "        time_diffs = []\n",
    "        for i in range(min(100, len(all_data) - 1)):\n",
    "            dt = (all_data[i+1]['timestamp'] - all_data[i]['timestamp']).total_seconds() * 1000\n",
    "            time_diffs.append(dt)\n",
    "        \n",
    "        print(f\"\\n  æ™‚é–“é–“éš”çµ±è¨ˆï¼ˆå‰ 100 å¹€ï¼‰:\")\n",
    "        print(f\"    å¹³å‡: {np.mean(time_diffs):.1f}ms\")\n",
    "        print(f\"    æ¨™æº–å·®: {np.std(time_diffs):.1f}ms\")\n",
    "        print(f\"    æœ€å°å€¼: {min(time_diffs):.1f}ms\")\n",
    "        print(f\"    æœ€å¤§å€¼: {max(time_diffs):.1f}ms\")\n",
    "        print(f\"    é æœŸ: {FRAME_INTERVAL_MS:.1f}ms\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# è¼‰å…¥æ‰€æœ‰ thermal log\n",
    "log_files = sorted(THERMAL_DIR.glob('log*.txt'))\n",
    "\n",
    "if not log_files:\n",
    "    raise FileNotFoundError(f\"âŒ æœªæ‰¾åˆ° log æª”æ¡ˆæ–¼ {THERMAL_DIR}\")\n",
    "\n",
    "therm_data = load_thermal_data_with_global_counter(log_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f9cd6",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: åˆ†æ RGB å½±ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ced875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æ AVI å½±ç‰‡\n",
    "cap = cv2.VideoCapture(str(AVI_FILE))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡ {AVI_FILE}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "duration = frame_count / fps if fps > 0 else 0\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RGB å½±ç‰‡è³‡è¨Š\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  FPS: {fps:.2f}\")\n",
    "print(f\"  ç¸½å¹€æ•¸: {frame_count:,}\")\n",
    "print(f\"  è§£æåº¦: {width} Ã— {height}\")\n",
    "print(f\"  æ™‚é•·: {duration:.2f} ç§’\")\n",
    "print(f\"  é–‹å§‹æ™‚é–“: {camera_start_time}\")\n",
    "print(f\"  çµæŸæ™‚é–“: {camera_start_time + timedelta(seconds=duration)}\")\n",
    "print(f\"\\n  é æœŸ Thermal-RGB å¹€é–“éš”:\")\n",
    "print(f\"    Thermal é–“éš”: {FRAME_INTERVAL_MS:.1f}ms\")\n",
    "print(f\"    RGB é–“éš”: {1000/fps:.1f}ms\")\n",
    "print(f\"    æ¯å€‹ Thermal å°æ‡‰ RGB å¹€æ•¸: {FRAME_INTERVAL_MS / (1000/fps):.1f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca69d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: ç°¡åŒ–é…å°ï¼ˆç›´æ¥æŒ‰æ™‚é–“æˆ³é…å°ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54997815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_timestamp_pairing(\n",
    "    thermal_data: List[Dict],\n",
    "    camera_start_time: datetime,\n",
    "    fps: float,\n",
    "    frame_count: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    ç›´æ¥æŒ‰æ™‚é–“æˆ³é…å° Thermal å’Œ RGBï¼ˆç°¡åŒ–ç‰ˆï¼‰\n",
    "    \n",
    "    å„ªé»ï¼š\n",
    "    1. ä¸ä¿®æ”¹æ™‚é–“æˆ³\n",
    "    2. é‚è¼¯ç°¡å–®æ¸…æ™°\n",
    "    3. æ²’æœ‰ç´¯ç©èª¤å·®\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ç›´æ¥æ™‚é–“æˆ³é…å°\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    pairs = []\n",
    "    rgb_end_time = camera_start_time + timedelta(seconds=frame_count / fps)\n",
    "    \n",
    "    print(f\"\\né…å°ç¯„åœ:\")\n",
    "    print(f\"  Camera Start: {camera_start_time}\")\n",
    "    print(f\"  Camera End: {rgb_end_time}\")\n",
    "    \n",
    "    skipped_before = 0\n",
    "    skipped_after = 0\n",
    "    \n",
    "    for thermal_frame in tqdm(thermal_data, desc=\"é…å° Thermal-RGB\"):\n",
    "        thermal_ts = thermal_frame['timestamp']\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦åœ¨ RGB å½±ç‰‡æ™‚é–“ç¯„åœå…§\n",
    "        if thermal_ts < camera_start_time:\n",
    "            skipped_before += 1\n",
    "            continue\n",
    "        \n",
    "        if thermal_ts > rgb_end_time:\n",
    "            skipped_after += 1\n",
    "            continue\n",
    "        \n",
    "        # è¨ˆç®—å°æ‡‰çš„ RGB å¹€ç´¢å¼•\n",
    "        offset = (thermal_ts - camera_start_time).total_seconds()\n",
    "        rgb_frame_idx = int(round(offset * fps))\n",
    "        rgb_frame_idx = max(0, min(rgb_frame_idx, frame_count - 1))\n",
    "        \n",
    "        # è¨ˆç®—é…å°èª¤å·®\n",
    "        actual_time = rgb_frame_idx / fps\n",
    "        rgb_error = abs(actual_time - offset)\n",
    "        \n",
    "        pairs.append({\n",
    "            'pair_id': f'pair_{len(pairs):05d}',\n",
    "            'thermal': thermal_frame,\n",
    "            'rgb_frame_idx': rgb_frame_idx,\n",
    "            'timestamp': thermal_ts,\n",
    "            'frame_number': thermal_frame['frame_number'],\n",
    "            'rgb_error_ms': rgb_error * 1000\n",
    "        })\n",
    "    \n",
    "    print(f\"\\né…å°çµæœ:\")\n",
    "    print(f\"  ç¸½é…å°æ•¸: {len(pairs):,}\")\n",
    "    print(f\"  è·³éï¼ˆå¤ªæ—©ï¼‰: {skipped_before}\")\n",
    "    print(f\"  è·³éï¼ˆå¤ªæ™šï¼‰: {skipped_after}\")\n",
    "    print(f\"  æˆåŠŸç‡: {len(pairs) / len(thermal_data) * 100:.1f}%\")\n",
    "    \n",
    "    if pairs:\n",
    "        rgb_errors = [p['rgb_error_ms'] for p in pairs]\n",
    "        print(f\"\\n  RGB é…å°èª¤å·®:\")\n",
    "        print(f\"    å¹³å‡: {np.mean(rgb_errors):.2f}ms\")\n",
    "        print(f\"    ä¸­ä½æ•¸: {np.median(rgb_errors):.2f}ms\")\n",
    "        print(f\"    æœ€å¤§å€¼: {max(rgb_errors):.2f}ms\")\n",
    "        \n",
    "        # RGB å¹€é–“éš”åˆ†ä½ˆ\n",
    "        rgb_indices = [p['rgb_frame_idx'] for p in pairs]\n",
    "        intervals = [rgb_indices[i+1] - rgb_indices[i] for i in range(len(rgb_indices) - 1)]\n",
    "        interval_counts = Counter(intervals)\n",
    "        \n",
    "        print(f\"\\n  RGB å¹€é–“éš”åˆ†ä½ˆ:\")\n",
    "        for interval in sorted(interval_counts.keys())[:10]:\n",
    "            count = interval_counts[interval]\n",
    "            percentage = count / len(intervals) * 100\n",
    "            print(f\"    é–“éš” {interval:3d} å¹€: {count:5d} æ¬¡ ({percentage:5.1f}%)\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# åŸ·è¡Œé…å°\n",
    "pairs_adaptive = direct_timestamp_pairing(\n",
    "    therm_data, camera_start_time, fps, frame_count\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Œ é…å°çµæœ: {len(pairs_adaptive):,} å°\")\n",
    "# ========================================\n",
    "# Step 5.5: ä¿®å¾©å¾Œé¢å¤§ Dropout\n",
    "# ========================================\n",
    "\n",
    "def analyze_and_fix_all_dropouts(thermal_data, camera_start_time, fps, frame_count):\n",
    "    \"\"\"\n",
    "    é€šç”¨ dropout ä¿®å¾©ï¼šä¸åªä¿®å¾Œé¢ï¼ŒæŠŠæ‰€æœ‰ dropout éƒ½ä¿®å¥½\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"å…¨é¢åˆ†æå’Œä¿®å¾© Dropoutï¼ˆé€šç”¨ç‰ˆï¼‰\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Step 1: åˆ†æ Thermal æ™‚é–“åˆ†ä½ˆ\n",
    "    sections = {}\n",
    "    for frame in thermal_data:\n",
    "        offset = (frame['timestamp'] - camera_start_time).total_seconds()\n",
    "        if offset < 0:\n",
    "            continue\n",
    "        second = int(offset)\n",
    "        if second not in sections:\n",
    "            sections[second] = []\n",
    "        sections[second].append(frame)\n",
    "    \n",
    "    if not sections:\n",
    "        print(\"âŒ ç„¡è³‡æ–™\")\n",
    "        return []\n",
    "    \n",
    "    min_sec = min(sections.keys())\n",
    "    max_sec = max(sections.keys())\n",
    "    \n",
    "    print(f\"\\n1ï¸âƒ£ æ™‚é–“åˆ†ä½ˆåˆ†æ:\")\n",
    "    print(f\"   æ™‚é–“ç¯„åœ: ç¬¬ {min_sec} ~ {max_sec} ç§’\")\n",
    "    \n",
    "    # çµ±è¨ˆæ¯ç§’çš„å¹€æ•¸\n",
    "    sec_counts = {sec: len(frames) for sec, frames in sections.items()}\n",
    "    \n",
    "    print(f\"   æ­£å¸¸ç§’ (8å¹€): {sum(1 for c in sec_counts.values() if c == 8)} ç§’\")\n",
    "    print(f\"   å°‘å¹€ç§’: {sum(1 for c in sec_counts.values() if 0 < c < 8)} ç§’\")\n",
    "    print(f\"   å¤šå¹€ç§’: {sum(1 for c in sec_counts.values() if c > 8)} ç§’\")\n",
    "    print(f\"   ç¼ºå¤±ç§’: {max_sec - min_sec + 1 - len(sections)} ç§’\")\n",
    "    \n",
    "    # Step 2: ç‚ºç¼ºå¤±çš„ç§’å»ºç«‹ç©º section\n",
    "    for sec in range(min_sec, max_sec + 1):\n",
    "        if sec not in sections:\n",
    "            sections[sec] = []\n",
    "    \n",
    "    # Step 3: åˆ†é¡\n",
    "    burst_secs = {}  # å¤šå¹€\n",
    "    dropout_secs = []  # å°‘å¹€æˆ–ç„¡å¹€\n",
    "    \n",
    "    for sec in range(min_sec, max_sec + 1):\n",
    "        count = len(sections[sec])\n",
    "        if count == 0 or count < 8:\n",
    "            dropout_secs.append(sec)\n",
    "        elif count > 8:\n",
    "            burst_secs[sec] = count\n",
    "    \n",
    "    print(f\"\\n2ï¸âƒ£ å•é¡Œç§’åˆ†é¡:\")\n",
    "    print(f\"   Burst ç§’: {len(burst_secs)} ç§’\")\n",
    "    print(f\"   Dropout ç§’: {len(dropout_secs)} ç§’\")\n",
    "    \n",
    "    # Step 4: æ™ºèƒ½åˆ†é…\n",
    "    print(f\"\\n3ï¸âƒ£ å¹€é‡æ–°åˆ†é…:\")\n",
    "    \n",
    "    total_redistributed = 0\n",
    "    \n",
    "    # ç­–ç•¥ï¼šå¾ burst ç§’å–å¤šé¤˜çš„å¹€ï¼Œåˆ†é…çµ¦å‰é¢æˆ–å‘¨åœçš„ dropout ç§’\n",
    "    for burst_sec in sorted(burst_secs.keys()):\n",
    "        frames = sections[burst_sec]\n",
    "        excess_count = len(frames) - 8\n",
    "        \n",
    "        # æ‰¾é™„è¿‘çš„ dropoutï¼ˆå„ªå…ˆå‰é¢ï¼Œå†çœ‹å¾Œé¢ï¼‰\n",
    "        nearby_dropouts = []\n",
    "        \n",
    "        # å¾€å‰æ‰¾ï¼ˆåœ¨ burst ç§’å‰é¢ï¼‰\n",
    "        for ds in sorted(dropout_secs, reverse=True):\n",
    "            if ds < burst_sec:\n",
    "                needed = 8 - len(sections[ds])\n",
    "                if needed > 0:\n",
    "                    nearby_dropouts.append((ds, needed))\n",
    "        \n",
    "        if not nearby_dropouts:\n",
    "            # å¾€å¾Œæ‰¾\n",
    "            for ds in sorted(dropout_secs):\n",
    "                if ds > burst_sec:\n",
    "                    needed = 8 - len(sections[ds])\n",
    "                    if needed > 0:\n",
    "                        nearby_dropouts.append((ds, needed))\n",
    "        \n",
    "        if not nearby_dropouts:\n",
    "            print(f\"   ç¬¬ {burst_sec} ç§’: {excess_count} å¹€å¤šé¤˜ï¼Œç„¡å¯åˆ†é…ï¼ˆä¸Ÿæ£„ï¼‰\")\n",
    "            sections[burst_sec] = frames[-8:]\n",
    "            continue\n",
    "        \n",
    "        # åˆ†é…\n",
    "        excess_frames = frames[:excess_count]\n",
    "        sections[burst_sec] = frames[excess_count:]\n",
    "        \n",
    "        frame_idx = 0\n",
    "        for dropout_sec, needed in nearby_dropouts:\n",
    "            if frame_idx >= len(excess_frames):\n",
    "                break\n",
    "            \n",
    "            available = min(needed, len(excess_frames) - frame_idx)\n",
    "            \n",
    "            for i in range(available):\n",
    "                frame = excess_frames[frame_idx]\n",
    "                \n",
    "                # ä¿®æ­£æ™‚é–“æˆ³\n",
    "                frame_in_sec = len(sections[dropout_sec])\n",
    "                new_ms = int(frame_in_sec * FRAME_INTERVAL_MS)\n",
    "                new_ts = camera_start_time + timedelta(seconds=dropout_sec, milliseconds=new_ms)\n",
    "                frame['timestamp'] = new_ts\n",
    "                \n",
    "                sections[dropout_sec].append(frame)\n",
    "                frame_idx += 1\n",
    "            \n",
    "            print(f\"   ç¬¬ {burst_sec} ç§’ â†’ ç¬¬ {dropout_sec} ç§’: è£œ {available} å¹€\")\n",
    "        \n",
    "        total_redistributed += frame_idx\n",
    "    \n",
    "    print(f\"   ç¸½é‡æ–°åˆ†é…: {total_redistributed} å¹€\")\n",
    "    \n",
    "    # Step 5: é…å°\n",
    "    print(f\"\\n4ï¸âƒ£ æœ€çµ‚é…å°:\")\n",
    "    \n",
    "    pairs = []\n",
    "    rgb_end_time = camera_start_time + timedelta(seconds=frame_count / fps)\n",
    "    \n",
    "    for sec in sorted(sections.keys()):\n",
    "        for thermal_frame in sections[sec]:\n",
    "            thermal_ts = thermal_frame['timestamp']\n",
    "            \n",
    "            if thermal_ts < camera_start_time or thermal_ts > rgb_end_time:\n",
    "                continue\n",
    "            \n",
    "            offset = (thermal_ts - camera_start_time).total_seconds()\n",
    "            rgb_frame_idx = int(round(offset * fps))\n",
    "            rgb_frame_idx = max(0, min(rgb_frame_idx, frame_count - 1))\n",
    "            \n",
    "            actual_time = rgb_frame_idx / fps\n",
    "            rgb_error = abs(actual_time - offset)\n",
    "            \n",
    "            pairs.append({\n",
    "                'pair_id': f'pair_{len(pairs):05d}',\n",
    "                'thermal': thermal_frame,\n",
    "                'rgb_frame_idx': rgb_frame_idx,\n",
    "                'timestamp': thermal_ts,\n",
    "                'frame_number': thermal_frame['frame_number'],\n",
    "                'rgb_error_ms': rgb_error * 1000\n",
    "            })\n",
    "    \n",
    "    print(f\"   ç¸½é…å°æ•¸: {len(pairs):,}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# ç›´æ¥ç”¨é€™å€‹å–ä»£ Step 5\n",
    "pairs_adaptive = analyze_and_fix_all_dropouts(therm_data, camera_start_time, fps, frame_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe8a86",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: æ™‚é–“åŒæ­¥è¨ºæ–·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c21530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_timing_sync(pairs: List[Dict], camera_start_time: datetime, fps: float, output_dir: Path):\n",
    "    \"\"\"\n",
    "    è¨ºæ–·æ™‚é–“åŒæ­¥å•é¡Œ\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"æ™‚é–“åŒæ­¥è¨ºæ–·\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # è¨ˆç®—æ¯å€‹é…å°çš„æ™‚é–“åç§»\n",
    "    time_offsets = []\n",
    "    \n",
    "    for pair in pairs[:min(500, len(pairs))]:\n",
    "        thermal_ts = pair['timestamp']\n",
    "        rgb_frame_idx = pair['rgb_frame_idx']\n",
    "        \n",
    "        # RGB çš„å¯¦éš›æ™‚é–“\n",
    "        rgb_actual_time = camera_start_time + timedelta(seconds=rgb_frame_idx / fps)\n",
    "        \n",
    "        # æ™‚é–“å·®ï¼ˆæ­£å€¼ = Thermal æ…¢æ–¼ RGBï¼‰\n",
    "        time_diff = (thermal_ts - rgb_actual_time).total_seconds()\n",
    "        time_offsets.append(time_diff)\n",
    "    \n",
    "    mean_offset = np.mean(time_offsets)\n",
    "    std_offset = np.std(time_offsets)\n",
    "    \n",
    "    print(f\"\\næ™‚é–“åç§»çµ±è¨ˆï¼ˆå‰ {len(time_offsets)} å€‹é…å°ï¼‰:\")\n",
    "    print(f\"  å¹³å‡: {mean_offset:.3f} ç§’\")\n",
    "    print(f\"  æ¨™æº–å·®: {std_offset:.3f} ç§’\")\n",
    "    print(f\"  æœ€å°å€¼: {min(time_offsets):.3f} ç§’\")\n",
    "    print(f\"  æœ€å¤§å€¼: {max(time_offsets):.3f} ç§’\")\n",
    "    \n",
    "    # è¦–è¦ºåŒ–\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # æ™‚é–“å·®åˆ†å¸ƒ\n",
    "    axes[0].hist(time_offsets, bins=50, edgecolor='black', alpha=0.7, color='#ff6b6b')\n",
    "    axes[0].axvline(mean_offset, color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {mean_offset:.3f}s')\n",
    "    axes[0].axvline(0, color='green', linestyle='-', linewidth=1, alpha=0.5,\n",
    "                    label='Perfect Sync')\n",
    "    axes[0].set_xlabel('Time Offset (seconds, positive = Thermal slower)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('Thermal-RGB Time Offset Distribution')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ™‚é–“å·®è¶¨å‹¢\n",
    "    axes[1].plot(range(len(time_offsets)), time_offsets, 'b-', linewidth=1, alpha=0.7)\n",
    "    axes[1].axhline(mean_offset, color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {mean_offset:.3f}s')\n",
    "    axes[1].axhline(0, color='green', linestyle='-', linewidth=1, alpha=0.5,\n",
    "                    label='Perfect Sync')\n",
    "    axes[1].set_xlabel('Pair Index')\n",
    "    axes[1].set_ylabel('Time Offset (seconds)')\n",
    "    axes[1].set_title('Time Offset Trend Over Time')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = output_dir / 'timing_diagnosis_v4.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nâœ… è¨ºæ–·åœ–å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    if abs(mean_offset) > 0.5:\n",
    "        print(f\"\\nâš ï¸ è­¦å‘Šï¼šæ™‚é–“åç§»è¶…é 0.5 ç§’ï¼\")\n",
    "        print(f\"   å»ºè­°ä¿®æ­£ camera_start_time:\")\n",
    "        corrected = camera_start_time + timedelta(seconds=mean_offset)\n",
    "        print(f\"   camera_start_time = datetime({corrected.year}, {corrected.month}, {corrected.day}, \")\n",
    "        print(f\"                                {corrected.hour}, {corrected.minute}, {corrected.second})\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… æ™‚é–“åŒæ­¥è‰¯å¥½ï¼ˆåç§» < 0.5 ç§’ï¼‰\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "\n",
    "# åŸ·è¡Œè¨ºæ–·\n",
    "diagnose_timing_sync(pairs_adaptive, camera_start_time, fps, DIAGNOSTIC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_diagnostics(pairs: List[Dict], camera_start_time: datetime, fps: float) -> Dict:\n",
    "    \"\"\"\n",
    "    è©³ç´°è¨ºæ–·ï¼šæ‰¾å‡º RGB FPS å’Œ Thermal æ™‚é–“æˆ³çš„çœŸå¯¦æƒ…æ³\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"è©³ç´°è¨ºæ–·ï¼šæ‰¾å‡ºçœŸæ­£çš„å»¶é²åŸå› \")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if len(pairs) < 100:\n",
    "        print(\"é…å°æ•¸é‡å¤ªå°‘ï¼Œç„¡æ³•è¨ºæ–·\")\n",
    "        return {}\n",
    "    \n",
    "    # ========== è¨ºæ–· 1: RGB å¹€åºåˆ—çš„çœŸå¯¦ FPS ==========\n",
    "    print(f\"\\nã€è¨ºæ–· 1ã€‘RGB å¹€åºåˆ—åˆ†æ:\")\n",
    "    \n",
    "    rgb_indices = [p['rgb_frame_idx'] for p in pairs]\n",
    "    \n",
    "    # è¨ˆç®—æ¯ 100 å€‹é…å°çš„ RGB å¹€æ¶ˆè€—\n",
    "    intervals_100 = []\n",
    "    for i in range(0, len(rgb_indices) - 100, 100):\n",
    "        rgb_consumed = rgb_indices[i+100] - rgb_indices[i]\n",
    "        intervals_100.append(rgb_consumed)\n",
    "    \n",
    "    if intervals_100:\n",
    "        print(f\"  æ¯ 100 å€‹ Thermal å¹€æ¶ˆè€—çš„ RGB å¹€æ•¸:\")\n",
    "        print(f\"    å¹³å‡: {np.mean(intervals_100):.2f} å¹€\")\n",
    "        print(f\"    æœ€å°: {np.min(intervals_100)} å¹€\")\n",
    "        print(f\"    æœ€å¤§: {np.max(intervals_100)} å¹€\")\n",
    "        print(f\"    æ¨™æº–å·®: {np.std(intervals_100):.2f} å¹€\")\n",
    "        print(f\"    é æœŸ: 308.375 å¹€ (100 * 24.67 / 8)\")\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦å‘ˆç·šæ€§è¶¨å‹¢\n",
    "        if len(intervals_100) > 1:\n",
    "            trend = intervals_100[-1] - intervals_100[0]\n",
    "            if abs(trend) > 2:\n",
    "                print(f\"  âš ï¸ æª¢æ¸¬åˆ°è¶¨å‹¢: {trend:+.2f} å¹€ (å¾é–‹å§‹åˆ°çµæŸ)\")\n",
    "                print(f\"    æ„å‘³è‘— RGB å¹€æ¶ˆè€—**åœ¨åŠ é€Ÿæˆ–æ¸›é€Ÿ**\")\n",
    "            else:\n",
    "                print(f\"  âœ“ æ²’æœ‰æ˜é¡¯è¶¨å‹¢\")\n",
    "    \n",
    "    # ========== è¨ºæ–· 2: Thermal æ™‚é–“æˆ³å‡å‹»æ€§ ==========\n",
    "    print(f\"\\nã€è¨ºæ–· 2ã€‘Thermal æ™‚é–“æˆ³å‡å‹»æ€§:\")\n",
    "    \n",
    "    thermal_times = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        offset = (pair['timestamp'] - camera_start_time).total_seconds()\n",
    "        thermal_times.append(offset)\n",
    "    \n",
    "    thermal_times = np.array(thermal_times)\n",
    "    \n",
    "    # è¨ˆç®—ç›¸é„°å¹€çš„æ™‚é–“å·®\n",
    "    time_intervals = np.diff(thermal_times)\n",
    "    \n",
    "    print(f\"  Thermal å¹€æ™‚é–“é–“éš”:\")\n",
    "    print(f\"    å¹³å‡: {np.mean(time_intervals)*1000:.2f} ms\")\n",
    "    print(f\"    æœ€å°: {np.min(time_intervals)*1000:.2f} ms\")\n",
    "    print(f\"    æœ€å¤§: {np.max(time_intervals)*1000:.2f} ms\")\n",
    "    print(f\"    æ¨™æº–å·®: {np.std(time_intervals)*1000:.2f} ms\")\n",
    "    print(f\"    é æœŸ: 125.00 ms\")\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ç•°å¸¸é–“éš”\n",
    "    abnormal_threshold = 125 + 10  # å…è¨± Â±10ms åå·®\n",
    "    abnormal_count = np.sum(time_intervals*1000 > abnormal_threshold)\n",
    "    \n",
    "    if abnormal_count > 0:\n",
    "        print(f\"  âš ï¸ æª¢æ¸¬åˆ° {abnormal_count} å€‹ç•°å¸¸é–“éš” (> {abnormal_threshold}ms)\")\n",
    "        \n",
    "        # æ‰¾å‡ºç•°å¸¸çš„å¹€\n",
    "        abnormal_indices = np.where(time_intervals*1000 > abnormal_threshold)[0]\n",
    "        print(f\"  ç•°å¸¸é–“éš”ä½ç½® (å‰ 10 å€‹):\")\n",
    "        for idx in abnormal_indices[:10]:\n",
    "            interval_ms = time_intervals[idx] * 1000\n",
    "            print(f\"    å¹€ {idx} â†’ {idx+1}: {interval_ms:.2f} ms\")\n",
    "    else:\n",
    "        print(f\"  âœ“ æ‰€æœ‰æ™‚é–“é–“éš”æ­£å¸¸\")\n",
    "    \n",
    "    # ========== è¨ºæ–· 3: é…å°èª¤å·®çš„ç´¯ç©è¶¨å‹¢ ==========\n",
    "    print(f\"\\nã€è¨ºæ–· 3ã€‘é…å°èª¤å·®ç´¯ç©è¶¨å‹¢:\")\n",
    "    \n",
    "    # è¨ˆç®—æ¯å€‹é…å°çš„ã€Œç†æƒ³ RGB ä½ç½®ã€vsã€Œå¯¦éš› RGB ä½ç½®ã€\n",
    "    errors = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        thermal_offset = (pair['timestamp'] - camera_start_time).total_seconds()\n",
    "        \n",
    "        # ç†æƒ³çš„ RGB å¹€ç´¢å¼•ï¼ˆå¦‚æœ RGB FPS å®Œå…¨æ˜¯ 25ï¼‰\n",
    "        ideal_rgb_idx = thermal_offset * fps\n",
    "        \n",
    "        # å¯¦éš›çš„ RGB å¹€ç´¢å¼•\n",
    "        actual_rgb_idx = pair['rgb_frame_idx']\n",
    "        \n",
    "        # èª¤å·®ï¼ˆå¹€æ•¸ï¼‰\n",
    "        error = actual_rgb_idx - ideal_rgb_idx\n",
    "        errors.append(error)\n",
    "    \n",
    "    errors = np.array(errors)\n",
    "    \n",
    "    print(f\"  é…å°èª¤å·®ï¼ˆå¯¦éš› - ç†æƒ³ï¼‰:\")\n",
    "    print(f\"    å¹³å‡: {np.mean(errors):+.4f} å¹€\")\n",
    "    print(f\"    æœ€å°: {np.min(errors):+.4f} å¹€\")\n",
    "    print(f\"    æœ€å¤§: {np.max(errors):+.4f} å¹€\")\n",
    "    print(f\"    æ¨™æº–å·®: {np.std(errors):.4f} å¹€\")\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ç·šæ€§è¶¨å‹¢\n",
    "    if len(errors) > 1:\n",
    "        x = np.arange(len(errors))\n",
    "        coeffs = np.polyfit(x, errors, 1)\n",
    "        slope = coeffs[0]\n",
    "        \n",
    "        print(f\"\\n  èª¤å·®ç·šæ€§è¶¨å‹¢:\")\n",
    "        print(f\"    æ–œç‡: {slope:.6f} å¹€/å°\")\n",
    "        print(f\"    é è¨ˆ 1000 å¹€å¾Œèª¤å·®: {slope * 1000:+.2f} å¹€\")\n",
    "        \n",
    "        if abs(slope) > 0.0001:\n",
    "            print(f\"  âš ï¸ æª¢æ¸¬åˆ°æ˜é¡¯çš„å–®å‘èª¤å·®ç´¯ç©\")\n",
    "            direction = \"è¶Šä¾†è¶Šå¿«\" if slope < 0 else \"è¶Šä¾†è¶Šæ…¢\"\n",
    "            print(f\"    Thermal é…å° {direction}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ èª¤å·®åŸºæœ¬ç©©å®š\")\n",
    "    \n",
    "    # ========== è¨ºæ–· 4: RGB FPS å¯¦éš›å€¼ ==========\n",
    "    print(f\"\\nã€è¨ºæ–· 4ã€‘å¯¦éš› RGB FPS è¨ˆç®—:\")\n",
    "    \n",
    "    # ç”¨ç¸½æ™‚é–“å’Œç¸½å¹€æ•¸æ¨ç®—\n",
    "    total_thermal_time = thermal_times[-1] - thermal_times[0]\n",
    "    total_rgb_frames = rgb_indices[-1] - rgb_indices[0]\n",
    "    \n",
    "    actual_fps = total_rgb_frames / total_thermal_time\n",
    "    \n",
    "    print(f\"  åŸºæ–¼é…å°æ•¸æ“šåæ¨:\")\n",
    "    print(f\"    ç¸½ Thermal æ™‚é•·: {total_thermal_time:.2f} ç§’\")\n",
    "    print(f\"    ç¸½ RGB å¹€æ¶ˆè€—: {total_rgb_frames} å¹€\")\n",
    "    print(f\"    å¯¦éš› RGB FPS: {actual_fps:.4f}\")\n",
    "    print(f\"    è¨­å®š RGB FPS: {fps:.4f}\")\n",
    "    print(f\"    å·®ç•°: {actual_fps - fps:+.4f}\")\n",
    "    \n",
    "    if abs(actual_fps - fps) > 0.1:\n",
    "        print(f\"  âš ï¸ å¯¦éš› FPS èˆ‡è¨­å®š FPS å·®ç•°å¤§\")\n",
    "        print(f\"    é€™å¯èƒ½æ˜¯å°è‡´å»¶é²çš„ä¸»è¦åŸå› \")\n",
    "    else:\n",
    "        print(f\"  âœ“ FPS åŸºæœ¬åŒ¹é…\")\n",
    "    \n",
    "    # ========== è¨ºæ–· 5: è¦–è¦ºåŒ– ==========\n",
    "    print(f\"\\nã€è¨ºæ–· 5ã€‘ç”Ÿæˆè¨ºæ–·åœ–è¡¨...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # å­åœ– 1: RGB å¹€æ¶ˆè€—è¶¨å‹¢\n",
    "    sample_indices = np.linspace(0, len(rgb_indices)-1, 100, dtype=int)\n",
    "    rgb_at_samples = [rgb_indices[i] for i in sample_indices]\n",
    "    thermal_at_samples = sample_indices.tolist()\n",
    "    \n",
    "    axes[0, 0].plot(thermal_at_samples, rgb_at_samples, 'b-', linewidth=2, label='Actual RGB frames')\n",
    "    \n",
    "    # ç†æƒ³ç·šï¼ˆFPS = 24.67ï¼‰\n",
    "    ideal_rgb = [idx * fps / 8 for idx in thermal_at_samples]\n",
    "    axes[0, 0].plot(thermal_at_samples, ideal_rgb, 'r--', linewidth=2, label=f'Ideal (FPS={fps:.2f})')\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Thermal Frame Index')\n",
    "    axes[0, 0].set_ylabel('RGB Frame Index')\n",
    "    axes[0, 0].set_title('RGB Frame Progression')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­åœ– 2: æ™‚é–“é–“éš”åˆ†ä½ˆ\n",
    "    axes[0, 1].hist(time_intervals*1000, bins=50, edgecolor='black', alpha=0.7, color='#4ecdc4')\n",
    "    axes[0, 1].axvline(125, color='red', linestyle='--', linewidth=2, label='Expected: 125ms')\n",
    "    axes[0, 1].set_xlabel('Time Interval (ms)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Thermal Frame Time Interval Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­åœ– 3: é…å°èª¤å·®è¶¨å‹¢\n",
    "    axes[1, 0].scatter(range(len(errors)), errors, alpha=0.3, s=5, color='#95e1d3')\n",
    "    if len(errors) > 1:\n",
    "        z = np.polyfit(range(len(errors)), errors, 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[1, 0].plot(range(len(errors)), p(range(len(errors))), 'r-', linewidth=2, label=f'Trend: {z[0]:.6f}x')\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Pair Index')\n",
    "    axes[1, 0].set_ylabel('Error (Frames)')\n",
    "    axes[1, 0].set_title('Pairing Error Trend')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­åœ– 4: æ¯ 100 å°çš„ RGB æ¶ˆè€—\n",
    "    axes[1, 1].plot(intervals_100 if intervals_100 else [0], 'go-', linewidth=2, markersize=6)\n",
    "    axes[1, 1].axhline(308.375, color='red', linestyle='--', linewidth=2, label='Expected: 308.375')\n",
    "    axes[1, 1].set_xlabel('Sample Index (per 100 pairs)')\n",
    "    axes[1, 1].set_ylabel('RGB Frames Consumed')\n",
    "    axes[1, 1].set_title('RGB Frame Consumption per 100 Thermal Frames')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Detailed Synchronization Diagnostics', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_path = DIAGNOSTIC_DIR / 'detailed_diagnostics.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  âœ“ è¨ºæ–·åœ–å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'thermal_interval_mean_ms': np.mean(time_intervals) * 1000,\n",
    "        'thermal_interval_std_ms': np.std(time_intervals) * 1000,\n",
    "        'error_slope': coeffs[0] if len(errors) > 1 else 0,\n",
    "        'actual_fps': actual_fps,\n",
    "        'expected_fps': fps\n",
    "    }\n",
    "\n",
    "# åŸ·è¡Œè©³ç´°è¨ºæ–·\n",
    "diagnostics = detailed_diagnostics(pairs_adaptive, camera_start_time, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863bc26",
   "metadata": {},
   "source": [
    "step6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721376a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Step 6.5: æ™‚é˜æ¼‚ç§»æ ¡æ­£\n",
    "# ========================================\n",
    "\n",
    "def apply_clock_drift_correction(pairs, camera_start_time, fps, frame_count, drift_rate_ms_per_second):\n",
    "    \"\"\"\n",
    "    æ‡‰ç”¨æ™‚é˜æ¼‚ç§»æ ¡æ­£\n",
    "    æ ¹æ“šæ¸¬å¾—çš„å»¶é²å¢é•·ç‡ï¼Œåå‘æ ¡æ­£ Thermal æ™‚é–“æˆ³\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"æ‡‰ç”¨æ™‚é˜æ¼‚ç§»æ ¡æ­£\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"æª¢æ¸¬åˆ°çš„æ¼‚ç§»ç‡: {drift_rate_ms_per_second:.3f} ms/s\")\n",
    "    print(f\"Thermal æ¯” RGB å¿« {drift_rate_ms_per_second/10:.3f}%\")\n",
    "    \n",
    "    corrected_pairs = []\n",
    "    \n",
    "    for i, pair in enumerate(pairs):\n",
    "        pair_new = pair.copy()\n",
    "        \n",
    "        # è¨ˆç®—é€™ä¸€å¹€åˆ°é–‹å§‹çš„æ™‚é–“å·®ï¼ˆç§’ï¼‰\n",
    "        elapsed_seconds = (pair['timestamp'] - pairs[0]['timestamp']).total_seconds()\n",
    "        \n",
    "        # è¨ˆç®—ç´¯ç©çš„æ¼‚ç§»ï¼ˆæ¯«ç§’ï¼‰\n",
    "        drift_accumulated_ms = elapsed_seconds * drift_rate_ms_per_second\n",
    "        \n",
    "        # æ ¡æ­£ï¼šæŠŠ Thermal å¾€å¾Œæ¨ï¼ˆå› ç‚ºå®ƒæ¯”è¼ƒå¿«ï¼‰\n",
    "        corrected_ts = pair['timestamp'] - timedelta(milliseconds=drift_accumulated_ms)\n",
    "        \n",
    "        # é‡æ–°è¨ˆç®— RGB å¹€ç´¢å¼•\n",
    "        offset_sec = (corrected_ts - camera_start_time).total_seconds()\n",
    "        rgb_frame_idx = int(round(offset_sec * fps))\n",
    "        rgb_frame_idx = max(0, min(rgb_frame_idx, frame_count - 1))\n",
    "        \n",
    "        pair_new['timestamp_original'] = pair['timestamp']\n",
    "        pair_new['timestamp_corrected'] = corrected_ts\n",
    "        pair_new['drift_correction_ms'] = drift_accumulated_ms\n",
    "        pair_new['rgb_frame_idx'] = rgb_frame_idx\n",
    "        \n",
    "        corrected_pairs.append(pair_new)\n",
    "    \n",
    "    print(f\"\\nâœ… æ ¡æ­£å®Œæˆ\")\n",
    "    print(f\"  ç¬¬ä¸€å¹€æ ¡æ­£: 0.00 ms\")\n",
    "    print(f\"  ä¸­é–“å¹€æ ¡æ­£: {(pairs[len(pairs)//2]['timestamp'] - pairs[0]['timestamp']).total_seconds() * drift_rate_ms_per_second:.2f} ms\")\n",
    "    print(f\"  æœ€å¾Œå¹€æ ¡æ­£: {(pairs[-1]['timestamp'] - pairs[0]['timestamp']).total_seconds() * drift_rate_ms_per_second:.2f} ms\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return corrected_pairs\n",
    "\n",
    "# æ ¹æ“šä½ çš„æ¸¬é‡æ•¸æ“š\n",
    "# å»¶é²: å¾ 0ms (0:00) â†’ 2700ms (6:50)\n",
    "# æ™‚é•·: 410 ç§’\n",
    "measured_drift_rate_ms_per_second = 2700 / 410  # å¤§ç´„ 6.59 ms/s\n",
    "\n",
    "print(f\"\\nè¨ˆç®—æ¼‚ç§»ç‡:\")\n",
    "print(f\"  æ¸¬é‡å»¶é²: 2700 ms\")\n",
    "print(f\"  éŒ„è£½æ™‚é•·: 410 ç§’\")\n",
    "print(f\"  æ¼‚ç§»ç‡: {measured_drift_rate_ms_per_second:.3f} ms/s\")\n",
    "\n",
    "# æ‡‰ç”¨æ ¡æ­£\n",
    "pairs_final = apply_clock_drift_correction(\n",
    "    pairs_adaptive, \n",
    "    camera_start_time, \n",
    "    fps,\n",
    "    frame_count,\n",
    "    measured_drift_rate_ms_per_second\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe228d51",
   "metadata": {},
   "source": [
    "step6.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc35117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def optimize_pairing_with_accumulator(pairs: List[Dict], fps: float, frame_count: int, target_thermal_fps: int = 8) -> List[Dict]:\n",
    "    #ä½¿ç”¨æµ®é»ç´¯ç©è¨ˆæ•¸å™¨æ¶ˆé™¤å–®å‘å»¶é²\n",
    "    \n",
    "    #æ ¸å¿ƒæƒ³æ³•ï¼š\n",
    "    #1. ç¬¬ä¸€å¹€ä½œç‚ºåŸºæº–é»ï¼ˆä¿æŒä¸è®Šï¼‰\n",
    "    #2. ç”¨æµ®é»ç´¯ç©å™¨è¿½è¹¤ç²¾ç¢ºçš„ RGB ä½ç½®ï¼ˆä¸æ˜¯æ•´æ•¸ï¼‰\n",
    "    #3. æ¯ä¸€å¹€å¢åŠ ç²¾ç¢ºçš„é–“éš”å€¼\n",
    "    #4. åªåœ¨æœ€å¾Œå››æ¨äº”å…¥ï¼Œä¿æŒæµ®é»ç²¾åº¦\n",
    "    #5. çµæœï¼šèª¤å·®è¢«é™åˆ¶åœ¨ Â±0.5 å¹€ï¼Œä¸æœƒå–®å‘ç´¯ç©\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"V5.1: ç´¯ç©è¨ˆæ•¸å™¨å„ªåŒ–ï¼ˆæ¶ˆé™¤å–®å‘å»¶é²ï¼‰\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        return pairs\n",
    "    \n",
    "    # é æœŸçš„ RGB å¹€é–“éš”ï¼ˆæµ®é»æ•¸ï¼‰\n",
    "    expected_interval = fps / target_thermal_fps\n",
    "    \n",
    "    print(f\"\\né…ç½®:\")\n",
    "    print(f\"  Thermal FPS: {target_thermal_fps}\")\n",
    "    print(f\"  RGB FPS: {fps:.2f}\")\n",
    "    print(f\"  é æœŸ RGB é–“éš”: {expected_interval:.5f} å¹€\")\n",
    "    \n",
    "    optimized_pairs = []\n",
    "    \n",
    "    # ç¬¬ä¸€å¹€ä¿æŒåŸæ¨£ï¼ˆä½œç‚ºåŸºæº–ï¼‰\n",
    "    first_pair = pairs[0].copy()\n",
    "    first_pair['accumulated_rgb_position'] = float(first_pair['rgb_frame_idx'])\n",
    "    first_pair['rounding_error_ms'] = 0.0\n",
    "    optimized_pairs.append(first_pair)\n",
    "    \n",
    "    # æµ®é»ç´¯ç©è¨ˆæ•¸å™¨ï¼ˆå¾ç¬¬ä¸€å¹€é–‹å§‹ï¼‰\n",
    "    accumulated_rgb_position = float(pairs[0]['rgb_frame_idx'])\n",
    "    \n",
    "    rounding_errors = [0.0]  # è¿½è¹¤æ¯ä¸€å¹€çš„å››æ¨äº”å…¥èª¤å·®\n",
    "    interval_corrections = []\n",
    "    \n",
    "    print(f\"\\né–‹å§‹å„ªåŒ–é…å°...\")\n",
    "    \n",
    "    for i in range(1, len(pairs)):\n",
    "        # å¢åŠ ç²¾ç¢ºçš„é–“éš”ï¼ˆæµ®é»æ•¸ï¼‰\n",
    "        accumulated_rgb_position += expected_interval\n",
    "        \n",
    "        # å››æ¨äº”å…¥åˆ°æœ€è¿‘çš„å¹€\n",
    "        new_rgb_idx = int(round(accumulated_rgb_position))\n",
    "        \n",
    "        # ç¢ºä¿ä¸è¶…éé‚Šç•Œ\n",
    "        new_rgb_idx = max(0, min(new_rgb_idx, frame_count - 1))\n",
    "        \n",
    "        # è¨ˆç®—é€™ä¸€æ­¥çš„å››æ¨äº”å…¥èª¤å·®\n",
    "        rounding_error = accumulated_rgb_position - new_rgb_idx\n",
    "        rounding_errors.append(rounding_error)\n",
    "        \n",
    "        # è¨ˆç®—èˆ‡ä¸Šä¸€å¹€çš„ RGB é–“éš”\n",
    "        prev_rgb_idx = optimized_pairs[-1]['rgb_frame_idx']\n",
    "        interval = new_rgb_idx - prev_rgb_idx\n",
    "        interval_corrections.append(interval)\n",
    "        \n",
    "        # å»ºç«‹å„ªåŒ–å¾Œçš„é…å°\n",
    "        pair_opt = pairs[i].copy()\n",
    "        pair_opt['rgb_frame_idx_original'] = pairs[i]['rgb_frame_idx']\n",
    "        pair_opt['rgb_frame_idx'] = new_rgb_idx\n",
    "        pair_opt['accumulated_rgb_position'] = accumulated_rgb_position\n",
    "        pair_opt['rounding_error'] = rounding_error\n",
    "        pair_opt['rgb_interval_from_prev'] = interval\n",
    "        \n",
    "        optimized_pairs.append(pair_opt)\n",
    "        \n",
    "        # æ¯ 1000 å¹€æ‰“å°é€²åº¦\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  å·²è™•ç† {i+1:,} / {len(pairs):,} å°\")\n",
    "    \n",
    "    print(f\"\\nâœ… å„ªåŒ–å®Œæˆ\")\n",
    "    print(f\"  ç¸½å°æ•¸: {len(optimized_pairs):,}\")\n",
    "    \n",
    "    # è©³ç´°åˆ†æ\n",
    "    print(f\"\\nå››æ¨äº”å…¥èª¤å·®åˆ†æ:\")\n",
    "    rounding_errors = np.array(rounding_errors)\n",
    "    print(f\"  å¹³å‡: {np.mean(rounding_errors):+.4f} å¹€\")\n",
    "    print(f\"  æœ€å°: {np.min(rounding_errors):+.4f} å¹€\")\n",
    "    print(f\"  æœ€å¤§: {np.max(rounding_errors):+.4f} å¹€\")\n",
    "    print(f\"  æ¨™æº–å·®: {np.std(rounding_errors):.4f} å¹€\")\n",
    "    \n",
    "    # é—œéµæŒ‡æ¨™ï¼šèª¤å·®æ˜¯å¦è¢«é™åˆ¶åœ¨ Â±0.5\n",
    "    out_of_range = np.sum(np.abs(rounding_errors) > 0.5)\n",
    "    if out_of_range == 0:\n",
    "        print(f\"  âœ… æ‰€æœ‰èª¤å·®éƒ½åœ¨ Â±0.5 å¹€ç¯„åœå…§ï¼ˆå®Œç¾ï¼‰\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ æœ‰ {out_of_range} å€‹èª¤å·®è¶…é Â±0.5 å¹€\")\n",
    "    \n",
    "    # RGB å¹€é–“éš”åˆ†æ\n",
    "    print(f\"\\nRGB å¹€é–“éš”åˆ†æ:\")\n",
    "    interval_corrections = np.array(interval_corrections)\n",
    "    \n",
    "    from collections import Counter\n",
    "    interval_counter = Counter(interval_corrections)\n",
    "    \n",
    "    print(f\"  æœ€å¸¸è¦‹é–“éš”: {sorted(interval_counter.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n",
    "    print(f\"  é–“éš”å¹³å‡: {np.mean(interval_corrections):.4f} å¹€\")\n",
    "    print(f\"  é–“éš”æ¨™æº–å·®: {np.std(interval_corrections):.4f} å¹€\")\n",
    "    print(f\"  é–“éš”æœ€å°å€¼: {np.min(interval_corrections)} å¹€\")\n",
    "    print(f\"  é–“éš”æœ€å¤§å€¼: {np.max(interval_corrections)} å¹€\")\n",
    "    \n",
    "    # èª¤å·®è¶¨å‹¢åˆ†æï¼ˆæª¢æŸ¥æ˜¯å¦æœ‰å–®å‘ç´¯ç©ï¼‰\n",
    "    print(f\"\\nèª¤å·®è¶¨å‹¢åˆ†æï¼ˆæª¢æŸ¥å–®å‘ç´¯ç©ï¼‰:\")\n",
    "    sample_points = [0, len(rounding_errors)//4, len(rounding_errors)//2, \n",
    "                     3*len(rounding_errors)//4, len(rounding_errors)-1]\n",
    "    \n",
    "    print(f\"  {'ä½ç½®':>10} | {'èª¤å·®':>10} | è¶¨å‹¢\")\n",
    "    print(f\"  {'-'*35}\")\n",
    "    for j, pos in enumerate(sample_points):\n",
    "        if pos < len(rounding_errors):\n",
    "            error = rounding_errors[pos]\n",
    "            print(f\"  {pos:10d} | {error:+10.4f} | \", end=\"\")\n",
    "            \n",
    "            if j == 0:\n",
    "                print(\"(èµ·å§‹)\")\n",
    "            elif j == len(sample_points) - 1:\n",
    "                if abs(error) < 0.2:\n",
    "                    print(\"âœ… (ç©©å®š)\")\n",
    "                else:\n",
    "                    print(\"âš ï¸ (åé›¢)\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return optimized_pairs\n",
    "\n",
    "# åŸ·è¡Œ V5.1 å„ªåŒ–\n",
    "pairs_final = optimize_pairing_with_accumulator(pairs_adaptive, fps, frame_count, target_thermal_fps=8)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3131fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(f\"\\n{'='*70}\")\n",
    "print(f\"V5.1 æ•ˆæœé©—è­‰ï¼ˆå°æ¯” V4 vs V5.1ï¼‰\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# V4ï¼ˆåŸå§‹ï¼‰çš„ RGB å¹€é–“éš”\n",
    "rgb_intervals_v4 = []\n",
    "for i in range(1, min(500, len(pairs_adaptive))):\n",
    "    interval = pairs_adaptive[i]['rgb_frame_idx'] - pairs_adaptive[i-1]['rgb_frame_idx']\n",
    "    rgb_intervals_v4.append(interval)\n",
    "\n",
    "# V5.1ï¼ˆå„ªåŒ–ï¼‰çš„ RGB å¹€é–“éš”\n",
    "rgb_intervals_v5 = []\n",
    "for i in range(1, min(500, len(pairs_final))):\n",
    "    interval = pairs_final[i]['rgb_frame_idx'] - pairs_final[i-1]['rgb_frame_idx']\n",
    "    rgb_intervals_v5.append(interval)\n",
    "\n",
    "rgb_intervals_v4 = np.array(rgb_intervals_v4)\n",
    "rgb_intervals_v5 = np.array(rgb_intervals_v5)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. RGB å¹€é–“éš”åˆ†ä½ˆå°æ¯”\n",
    "axes[0, 0].hist(rgb_intervals_v4, bins=range(0, max(rgb_intervals_v4)+2), \n",
    "                alpha=0.6, label='V4 (Original)', color='#ff6b6b', edgecolor='black')\n",
    "axes[0, 0].hist(rgb_intervals_v5, bins=range(0, max(rgb_intervals_v5)+2), \n",
    "                alpha=0.6, label='V5.1 (Accumulator)', color='#51cf66', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('RGB Frame Interval')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('RGB Frame Interval Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. RGB å¹€é–“éš”æ™‚é–“åºåˆ—\n",
    "sample_size = min(200, len(rgb_intervals_v4))\n",
    "axes[0, 1].plot(range(sample_size), rgb_intervals_v4[:sample_size], 'o-', \n",
    "               label='V4', alpha=0.6, markersize=3)\n",
    "axes[0, 1].plot(range(sample_size), rgb_intervals_v5[:sample_size], 's-', \n",
    "               label='V5.1', alpha=0.6, markersize=3)\n",
    "axes[0, 1].axhline(np.mean(rgb_intervals_v4), color='#ff6b6b', linestyle='--', \n",
    "                  label=f'V4 Mean: {np.mean(rgb_intervals_v4):.2f}')\n",
    "axes[0, 1].axhline(np.mean(rgb_intervals_v5), color='#51cf66', linestyle='--', \n",
    "                  label=f'V5.1 Mean: {np.mean(rgb_intervals_v5):.2f}')\n",
    "axes[0, 1].set_xlabel('Frame Index')\n",
    "axes[0, 1].set_ylabel('Interval (frames)')\n",
    "axes[0, 1].set_title(f'RGB Frame Interval Sequence (First {sample_size})')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. å››æ¨äº”å…¥èª¤å·®ç´¯ç©ï¼ˆV5.1 çš„æ ¸å¿ƒæŒ‡æ¨™ï¼‰\n",
    "rounding_errors = [p.get('rounding_error', 0) for p in pairs_final[1:]]\n",
    "rounding_errors = np.array(rounding_errors[:1000])  # å‰ 1000 å€‹\n",
    "\n",
    "axes[1, 0].scatter(range(len(rounding_errors)), rounding_errors, alpha=0.5, s=10, color='#4ecdc4')\n",
    "axes[1, 0].axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "axes[1, 0].axhline(0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Â±0.5 boundary')\n",
    "axes[1, 0].axhline(-0.5, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Frame Index')\n",
    "axes[1, 0].set_ylabel('Rounding Error (frames)')\n",
    "axes[1, 0].set_title('V5.1: Rounding Error Pattern')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. çµ±è¨ˆå°æ¯”è¡¨\n",
    "stats_data = {\n",
    "    'æŒ‡æ¨™': ['å¹³å‡é–“éš”', 'æ¨™æº–å·®', 'æœ€å°', 'æœ€å¤§', 'ç©©å®šæ€§'],\n",
    "    'V4': [\n",
    "        f\"{np.mean(rgb_intervals_v4):.4f}\",\n",
    "        f\"{np.std(rgb_intervals_v4):.4f}\",\n",
    "        f\"{np.min(rgb_intervals_v4)}\",\n",
    "        f\"{np.max(rgb_intervals_v4)}\",\n",
    "        f\"{(1-np.std(rgb_intervals_v4)/np.mean(rgb_intervals_v4))*100:.1f}%\"\n",
    "    ],\n",
    "    'V5.1': [\n",
    "        f\"{np.mean(rgb_intervals_v5):.4f}\",\n",
    "        f\"{np.std(rgb_intervals_v5):.4f}\",\n",
    "        f\"{np.min(rgb_intervals_v5)}\",\n",
    "        f\"{np.max(rgb_intervals_v5)}\",\n",
    "        f\"{(1-np.std(rgb_intervals_v5)/np.mean(rgb_intervals_v5))*100:.1f}%\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "axes[1, 1].axis('off')\n",
    "table = axes[1, 1].table(cellText=[[stats_data['æŒ‡æ¨™'][i], stats_data['V4'][i], stats_data['V5.1'][i]] \n",
    "                                   for i in range(len(stats_data['æŒ‡æ¨™']))],\n",
    "                        colLabels=['Metric', 'V4', 'V5.1'],\n",
    "                        cellLoc='center',\n",
    "                        loc='center',\n",
    "                        bbox=[0, 0, 1, 1])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "plt.suptitle('V4 vs V5.1 é…å°æ•ˆæœå°æ¯”', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = DIAGNOSTIC_DIR / 'v4_vs_v51_comparison.png'\n",
    "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nå°æ¯”åœ–å·²å„²å­˜: {save_path}\")\n",
    "\n",
    "# è¼¸å‡ºçµè«–\n",
    "print(f\"\\nçµè«–:\")\n",
    "if np.std(rgb_intervals_v5) < np.std(rgb_intervals_v4):\n",
    "    improvement = (1 - np.std(rgb_intervals_v5)/np.std(rgb_intervals_v4)) * 100\n",
    "    print(f\"  âœ… V5.1 æ”¹å–„äº† {improvement:.1f}%\")\n",
    "    print(f\"  RGB å¹€é–“éš”è®Šå¾—æ›´åŠ å‡å‹»\")\n",
    "    print(f\"  Thermal å»¶é²æ‡‰è©²è¢«æ¶ˆé™¤äº†\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ V5.1 æ²’æœ‰æ”¹å–„\")\n",
    "    print(f\"  å¯èƒ½éœ€è¦æª¢æŸ¥ RGB FPS çš„ç²¾ç¢ºå€¼\")\n",
    "\n",
    "print(\"=\"*70)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def optimize_with_error_diffusion(pairs: List[Dict], fps: float, frame_count: int, target_thermal_fps: int = 8) -> List[Dict]:\n",
    "    \n",
    "    ä½¿ç”¨èª¤å·®æ“´æ•£ï¼ˆError Diffusionï¼‰å„ªåŒ– RGB é–“éš”åˆ†ä½ˆ\n",
    "    \n",
    "    åŸç†ï¼š\n",
    "    æ¯å€‹ Thermal å¹€éœ€è¦ 3.08375 RGB å¹€\n",
    "    3 + 0.08375 = 3.08375\n",
    "    \n",
    "    ç´¯ç© 0.08375 Ã— 12 = 1.005 â‰ˆ 1\n",
    "    æ‰€ä»¥æ¯ 12 å€‹ Thermal å¹€ï¼ŒRGB éœ€è¦å¤šè·³ 1 å¹€\n",
    "    \n",
    "    é€™å€‹æ–¹æ³•æœƒæŠŠ 4-å¹€é–“éš”å‡å‹»åˆ†ä½ˆåˆ°æ•´å€‹åºåˆ—\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"æœ€å„ªæŒ¯ç›ªåˆ†ä½ˆï¼ˆèª¤å·®æ“´æ•£ï¼‰\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        return pairs\n",
    "    \n",
    "    expected_interval = fps / target_thermal_fps  # 3.08375\n",
    "    \n",
    "    print(f\"\\né…ç½®:\")\n",
    "    print(f\"  é æœŸ RGB é–“éš”: {expected_interval:.5f} å¹€\")\n",
    "    print(f\"  æ•´æ•¸éƒ¨åˆ†: {int(expected_interval)} å¹€\")\n",
    "    print(f\"  å°æ•¸éƒ¨åˆ†: {expected_interval - int(expected_interval):.5f} å¹€\")\n",
    "    \n",
    "    # è¨ˆç®—å‘¨æœŸï¼šå¤šä¹…éœ€è¦å¤šè·³ä¸€å¹€\n",
    "    fractional = expected_interval - int(expected_interval)\n",
    "    period = round(1 / fractional)  # å¤§ç´„æ˜¯ 12\n",
    "    \n",
    "    print(f\"  é€±æœŸ: æ¯ {period} å€‹ Thermal å¹€ï¼ŒRGB å¤šè·³ 1 å¹€\")\n",
    "    print(f\"  é©—è­‰: {period} Ã— {fractional:.5f} = {period * fractional:.5f} â‰ˆ 1 âœ“\")\n",
    "    \n",
    "    optimized_pairs = []\n",
    "    base_interval = int(expected_interval)  # 3\n",
    "    \n",
    "    # ç¬¬ä¸€å¹€ä¿æŒåŸæ¨£\n",
    "    first_pair = pairs[0].copy()\n",
    "    first_pair['interval_applied'] = 0\n",
    "    first_pair['accumulated_error'] = 0.0\n",
    "    optimized_pairs.append(first_pair)\n",
    "    \n",
    "    accumulated_error = 0.0\n",
    "    \n",
    "    for i in range(1, len(pairs)):\n",
    "        # ç´¯ç©èª¤å·®\n",
    "        accumulated_error += fractional\n",
    "        \n",
    "        # æ±ºå®šé€™ä¸€æ­¥ç”¨ 3 é‚„æ˜¯ 4\n",
    "        if accumulated_error >= 1.0:\n",
    "            interval = base_interval + 1\n",
    "            accumulated_error -= 1.0\n",
    "        else:\n",
    "            interval = base_interval\n",
    "        \n",
    "        # è¨ˆç®—æ–°çš„ RGB å¹€ç´¢å¼•\n",
    "        prev_rgb_idx = optimized_pairs[-1]['rgb_frame_idx']\n",
    "        new_rgb_idx = prev_rgb_idx + interval\n",
    "        \n",
    "        # é‚Šç•Œæª¢æŸ¥\n",
    "        new_rgb_idx = min(new_rgb_idx, frame_count - 1)\n",
    "        \n",
    "        pair_opt = pairs[i].copy()\n",
    "        pair_opt['rgb_frame_idx_original'] = pairs[i]['rgb_frame_idx']\n",
    "        pair_opt['rgb_frame_idx'] = new_rgb_idx\n",
    "        pair_opt['interval_applied'] = interval\n",
    "        pair_opt['accumulated_error'] = accumulated_error\n",
    "        \n",
    "        optimized_pairs.append(pair_opt)\n",
    "    \n",
    "    print(f\"\\nâœ… æœ€å„ªåŒ–å®Œæˆ\")\n",
    "    print(f\"  ç¸½å°æ•¸: {len(optimized_pairs):,}\")\n",
    "    \n",
    "    # åˆ†æçµæœ\n",
    "    intervals = [optimized_pairs[i+1]['interval_applied'] for i in range(len(optimized_pairs)-1)]\n",
    "    intervals = np.array(intervals)\n",
    "    \n",
    "    from collections import Counter\n",
    "    interval_dist = Counter(intervals)\n",
    "    \n",
    "    print(f\"\\nRGB å¹€é–“éš”åˆ†ä½ˆ:\")\n",
    "    for interval, count in sorted(interval_dist.items()):\n",
    "        percentage = count / len(intervals) * 100\n",
    "        print(f\"  é–“éš” {interval} å¹€: {count:5d} æ¬¡ ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # æª¢æŸ¥å‡å‹»æ€§\n",
    "    print(f\"\\nRGB å¹€é–“éš”çµ±è¨ˆ:\")\n",
    "    print(f\"  å¹³å‡: {np.mean(intervals):.5f} å¹€\")\n",
    "    print(f\"  æ¨™æº–å·®: {np.std(intervals):.5f} å¹€\")\n",
    "    print(f\"  æœ€å°: {np.min(intervals)} å¹€\")\n",
    "    print(f\"  æœ€å¤§: {np.max(intervals)} å¹€\")\n",
    "    \n",
    "    # æª¢æŸ¥ç¸½æ¶ˆè€—\n",
    "    total_rgb = optimized_pairs[-1]['rgb_frame_idx'] - optimized_pairs[0]['rgb_frame_idx']\n",
    "    expected_rgb = (len(pairs) - 1) * expected_interval\n",
    "    \n",
    "    print(f\"\\nç¸½ RGB æ¶ˆè€—é©—è­‰:\")\n",
    "    print(f\"  å¯¦éš›: {total_rgb} å¹€\")\n",
    "    print(f\"  é æœŸ: {expected_rgb:.1f} å¹€\")\n",
    "    print(f\"  èª¤å·®: {total_rgb - expected_rgb:+.1f} å¹€\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return optimized_pairs\n",
    "\n",
    "# åŸ·è¡Œèª¤å·®æ“´æ•£å„ªåŒ–\n",
    "pairs_final = optimize_with_error_diffusion(pairs_adaptive, fps, frame_count, target_thermal_fps=8)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1efec",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: ç”Ÿæˆé…å°é©—è­‰å½±ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_video(\n",
    "    pairs: list,\n",
    "    avi_path: Path,\n",
    "    camera_start_time: datetime,\n",
    "    output_path: Path,\n",
    "    num_samples: int = 500,\n",
    "    flip_thermal: bool = True,\n",
    "    flip_rgb: bool = False,\n",
    "    video_fps: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆé…å°é©—è­‰å½±ç‰‡ï¼ˆside-by-sideï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ç”Ÿæˆé…å°é©—è­‰å½±ç‰‡\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(avi_path))\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡\")\n",
    "        return False\n",
    "    \n",
    "    rgb_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # å–æ¨£ç­–ç•¥ï¼šå‡å‹»å–æ¨£æ•´å€‹æ™‚é–“ç¯„åœ\n",
    "    step = max(1, len(pairs) // num_samples)\n",
    "    sample_indices = list(range(0, min(len(pairs), num_samples * step), step))[:num_samples]\n",
    "    \n",
    "    print(f\"\\né…ç½®:\")\n",
    "    print(f\"  å–æ¨£æ•¸é‡: {len(sample_indices)}\")\n",
    "    print(f\"  å–æ¨£é–“éš”: æ¯ {step} å€‹é…å°å– 1 å€‹\")\n",
    "    print(f\"  è¼¸å‡º FPS: {video_fps}\")\n",
    "    \n",
    "    # è®€å–ç¬¬ä¸€å¹€ç²å–å°ºå¯¸\n",
    "    first_pair = pairs[sample_indices[0]]\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, first_pair['rgb_frame_idx'])\n",
    "    ret, first_rgb = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"âŒ ç„¡æ³•è®€å–ç¬¬ä¸€å¹€\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "    rgb_height, rgb_width = first_rgb.shape[:2]\n",
    "    \n",
    "    # å»ºç«‹ VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\n",
    "        str(output_path),\n",
    "        fourcc,\n",
    "        video_fps,\n",
    "        (rgb_width * 2, rgb_height)\n",
    "    )\n",
    "    \n",
    "    if not out.isOpened():\n",
    "        print(f\"âŒ ç„¡æ³•å»ºç«‹è¼¸å‡ºå½±ç‰‡\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, pair_idx in enumerate(tqdm(sample_indices, desc=\"ç”Ÿæˆå½±ç‰‡\")):\n",
    "        pair = pairs[pair_idx]\n",
    "        \n",
    "        try:\n",
    "            # Thermal\n",
    "            thermal = pair['thermal']['image'].copy()\n",
    "            if flip_thermal:\n",
    "                thermal = cv2.flip(thermal, 1)\n",
    "            \n",
    "            thermal_upscaled = cv2.resize(thermal, (rgb_width, rgb_height), \n",
    "                                          interpolation=cv2.INTER_CUBIC)\n",
    "            thermal_colored = cv2.applyColorMap(thermal_upscaled, cv2.COLORMAP_JET)\n",
    "            \n",
    "            # RGB\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, pair['rgb_frame_idx'])\n",
    "            ret, rgb = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            if flip_rgb:\n",
    "                rgb = cv2.flip(rgb, 1)\n",
    "            \n",
    "            # è¨ˆç®—æ™‚é–“å·®\n",
    "            thermal_ts = pair['timestamp']\n",
    "            rgb_ts = camera_start_time + timedelta(seconds=pair['rgb_frame_idx'] / rgb_fps)\n",
    "            time_diff = (thermal_ts - rgb_ts).total_seconds()\n",
    "            \n",
    "            # Thermal å´æ¨™ç±¤\n",
    "            y_pos = 40\n",
    "            labels_thermal = [\n",
    "                f\"THERMAL - Pair {pair_idx}\",\n",
    "                f\"Time: {thermal_ts.strftime('%H:%M:%S.%f')[:-3]}\",\n",
    "                f\"Frame: {pair['frame_number']}\",\n",
    "                f\"Progress: {idx+1}/{len(sample_indices)}\"\n",
    "            ]\n",
    "            \n",
    "            for label in labels_thermal:\n",
    "                cv2.putText(thermal_colored, label, (10, y_pos), font, 0.7, (255, 255, 255), 2)\n",
    "                y_pos += 30\n",
    "            \n",
    "            # RGB å´æ¨™ç±¤\n",
    "            y_pos = 40\n",
    "            text_color = (0, 255, 0) if abs(time_diff) < 0.5 else (0, 165, 255) if abs(time_diff) < 1.0 else (0, 0, 255)\n",
    "            \n",
    "            labels_rgb = [\n",
    "                f\"RGB - Frame {pair['rgb_frame_idx']}\",\n",
    "                f\"Time: {rgb_ts.strftime('%H:%M:%S.%f')[:-3]}\",\n",
    "                f\"Diff: {time_diff:+.3f}s\",\n",
    "                f\"Error: {pair['rgb_error_ms']:.2f}ms\"\n",
    "            ]\n",
    "            \n",
    "            for label in labels_rgb:\n",
    "                cv2.putText(rgb, label, (10, y_pos), font, 0.7, text_color, 2)\n",
    "                y_pos += 30\n",
    "            \n",
    "            # åˆä½µä¸¦å¯«å…¥\n",
    "            combined = np.hstack([thermal_colored, rgb])\n",
    "            out.write(combined)\n",
    "            success_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ è™•ç† Pair {pair_idx} æ™‚å‡ºéŒ¯: {e}\")\n",
    "            continue\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\nâœ… å½±ç‰‡ç”Ÿæˆå®Œæˆï¼\")\n",
    "    print(f\"  è¼¸å‡º: {output_path}\")\n",
    "    print(f\"  æˆåŠŸ: {success_count} å¹€\")\n",
    "    print(f\"  æ™‚é•·: {success_count/video_fps:.1f} ç§’\")\n",
    "    \n",
    "    if output_path.exists():\n",
    "        file_size = output_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  å¤§å°: {file_size:.2f} MB\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# ç”Ÿæˆé©—è­‰å½±ç‰‡\n",
    "video_path = OUTPUT_DIR / 'pairing_validation_v5_1.mp4'\n",
    "create_validation_video(\n",
    "    pairs=pairs_final,\n",
    "    avi_path=AVI_FILE,\n",
    "    camera_start_time=camera_start_time,\n",
    "    output_path=video_path,\n",
    "    num_samples=5000,\n",
    "    flip_thermal=FLIP_THERMAL,\n",
    "    flip_rgb=FLIP_RGB,\n",
    "    video_fps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a149d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Step 8: å»ºç«‹ LabelMe å°ˆæ¡ˆçµæ§‹\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"å»ºç«‹ LabelMe å°ˆæ¡ˆçµæ§‹\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# å»ºç«‹å­ç›®éŒ„\n",
    "images_dir = LABELME_DIR / 'images'\n",
    "annotations_dir = LABELME_DIR / 'annotations'\n",
    "\n",
    "images_dir.mkdir(exist_ok=True)\n",
    "annotations_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nå»ºç«‹ç›®éŒ„:\")\n",
    "print(f\"  Images: {images_dir}\")\n",
    "print(f\"  Annotations: {annotations_dir}\")\n",
    "\n",
    "# å¤šæ ¸åŒ¯å‡ºå‡½æ•¸\n",
    "def export_labelme_batch(args):\n",
    "    pairs_batch, avi_path, images_out_dir, flip_rgb, height, width = args\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(avi_path))\n",
    "    exported_count = 0\n",
    "    \n",
    "    for pair in pairs_batch:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, pair['rgb_frame_idx'])\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        if flip_rgb:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        pair_id = pair['pair_id'].replace('pair_', '')\n",
    "        filename = f\"frame_{pair_id}.jpg\"\n",
    "        \n",
    "        # å„²å­˜åœ–ç‰‡\n",
    "        save_path = images_out_dir / filename\n",
    "        cv2.imwrite(str(save_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "        \n",
    "        exported_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return exported_count\n",
    "\n",
    "# åˆ†æ‰¹è™•ç†\n",
    "print(f\"\\nåŒ¯å‡ºåœ–ç‰‡ï¼ˆä½¿ç”¨ {NUM_WORKERS} workersï¼‰...\")\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "batch_size = max(100, len(pairs_adaptive) // NUM_WORKERS)\n",
    "batches = [\n",
    "    (pairs_adaptive[i:i+batch_size], AVI_FILE, images_dir, FLIP_RGB, height, width)\n",
    "    for i in range(0, len(pairs_adaptive), batch_size)\n",
    "]\n",
    "\n",
    "total_exported = 0\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    results = list(tqdm(\n",
    "        executor.map(export_labelme_batch, batches),\n",
    "        total=len(batches),\n",
    "        desc=\"åŒ¯å‡ºåœ–ç‰‡\"\n",
    "    ))\n",
    "\n",
    "total_exported = sum(results)\n",
    "\n",
    "print(f\"âœ… åŒ¯å‡º {total_exported} å¼µåœ–ç‰‡\")\n",
    "\n",
    "# ç”Ÿæˆ classes.txtï¼ˆåªè¦ä¸‰å€‹é¡åˆ¥ï¼‰\n",
    "classes_content = \"\"\"posture_lying\n",
    "posture_sitting\n",
    "posture_falling\"\"\"\n",
    "\n",
    "classes_txt_path = LABELME_DIR / 'classes.txt'\n",
    "with open(classes_txt_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(classes_content)\n",
    "\n",
    "print(f\"âœ… ç”Ÿæˆ classes.txt (3 å€‹é¡åˆ¥)\")\n",
    "\n",
    "# ç”Ÿæˆ pairing_index.json\n",
    "print(f\"\\nç”Ÿæˆ pairing_index.json...\")\n",
    "\n",
    "index_data = {\n",
    "    'total_images': len(pairs_adaptive),\n",
    "    'thermal_rgb_pairs': [\n",
    "        {\n",
    "            'image': f\"frame_{pair['pair_id'].replace('pair_', '')}.jpg\",\n",
    "            'timestamp': pair['timestamp'].isoformat(),\n",
    "            'rgb_frame_idx': pair['rgb_frame_idx']\n",
    "        }\n",
    "        for pair in pairs_adaptive\n",
    "    ]\n",
    "}\n",
    "\n",
    "index_path = LABELME_DIR / 'pairing_index.json'\n",
    "with open(index_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… ç”Ÿæˆ pairing_index.json\")\n",
    "\n",
    "# ç”Ÿæˆç°¡çŸ­ README\n",
    "readme_content = f\"\"\"# LabelMe æ¨™è¨»å°ˆæ¡ˆ\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### 1. ç”¨ LabelMe æŒ‡ä»¤åŒ¯å‡º\n",
    "```bash\n",
    "cd {LABELME_DIR}\n",
    "labelme images --labels classes.txt --output annotations\"\"\"\n",
    "readme_path = LABELME_DIR / 'README.md'\n",
    "with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04382f71",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: è¦–è¦ºåŒ–é…å°åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7846578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–é…å°çµæœ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. RGB èª¤å·®åˆ†å¸ƒ\n",
    "rgb_errors = [p['rgb_error_ms'] for p in pairs_final]\n",
    "axes[0, 0].hist(rgb_errors, bins=50, edgecolor='black', alpha=0.7, color='#51cf66')\n",
    "axes[0, 0].axvline(np.mean(rgb_errors), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {np.mean(rgb_errors):.2f}ms')\n",
    "axes[0, 0].set_xlabel('RGB Error (ms)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('RGB Time Alignment Error Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. RGB å¹€é–“éš”åˆ†ä½ˆ\n",
    "rgb_indices = [p['rgb_frame_idx'] for p in pairs_final]\n",
    "intervals = [rgb_indices[i+1] - rgb_indices[i] for i in range(len(rgb_indices) - 1)]\n",
    "\n",
    "axes[0, 1].hist(intervals, bins=range(0, min(20, max(intervals)+2)), edgecolor='black', alpha=0.7, color='#74c0fc')\n",
    "expected_interval = FRAME_INTERVAL_MS / (1000 / fps)\n",
    "axes[0, 1].axvline(expected_interval, color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Expected: {expected_interval:.1f} frames')\n",
    "axes[0, 1].set_xlabel('RGB Frame Interval')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('RGB Frame Interval Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Thermal æ™‚é–“é–“éš”\n",
    "time_diffs = []\n",
    "for i in range(len(pairs_final) - 1):\n",
    "    dt = (pairs_final[i+1]['timestamp'] - pairs_final[i]['timestamp']).total_seconds() * 1000\n",
    "    time_diffs.append(dt)\n",
    "\n",
    "axes[1, 0].hist(time_diffs, bins=50, edgecolor='black', alpha=0.7, color='#ffa94d')\n",
    "axes[1, 0].axvline(FRAME_INTERVAL_MS, color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Expected: {FRAME_INTERVAL_MS:.1f}ms')\n",
    "axes[1, 0].set_xlabel('Thermal Time Interval (ms)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Thermal Frame Time Interval Distribution (Should be constant)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. RGB å¹€åºåˆ—è¶¨å‹¢\n",
    "sample_size = min(500, len(rgb_indices))\n",
    "axes[1, 1].plot(range(sample_size), rgb_indices[:sample_size], 'b-', linewidth=1, alpha=0.7)\n",
    "axes[1, 1].scatter(range(sample_size), rgb_indices[:sample_size], c='blue', s=10, alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Pair Index')\n",
    "axes[1, 1].set_ylabel('RGB Frame Index')\n",
    "axes[1, 1].set_title(f'RGB Frame Sequence (First {sample_size} Pairs)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = PAIRING_DIR / 'pairing_analysis_v4.png'\n",
    "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nâœ… è¦–è¦ºåŒ–å·²å„²å­˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f9d71",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: å„²å­˜é…å°çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜é…å°çµæœ\n",
    "pairs_export = []\n",
    "for pair in pairs_final:\n",
    "    pairs_export.append({\n",
    "        'pair_id': pair['pair_id'],\n",
    "        'rgb_frame_idx': pair['rgb_frame_idx'],\n",
    "        'timestamp': pair['timestamp'].isoformat(),\n",
    "        'frame_number': pair['frame_number'],\n",
    "        'rgb_error_ms': pair['rgb_error_ms']\n",
    "    })\n",
    "\n",
    "# å„²å­˜ JSON\n",
    "json_path = PAIRING_DIR / 'pairs_mapping_v4.json'\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(pairs_export, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# å„²å­˜ CSV\n",
    "csv_path = PAIRING_DIR / 'pairs_mapping_v4.csv'\n",
    "df_pairs = pd.DataFrame(pairs_export)\n",
    "df_pairs.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"é…å°çµæœå·²å„²å­˜\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  JSON: {json_path}\")\n",
    "print(f\"  CSV: {csv_path}\")\n",
    "print(f\"  ç¸½é…å°æ•¸: {len(pairs_export):,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914fb5d",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: é©—è­‰ä¿®æ­£çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93372b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚é©—è­‰\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"æœ€çµ‚é©—è­‰å ±å‘Š\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nå‰ 20 å€‹é…å°:\")\n",
    "for i, pair in enumerate(pairs_final[:20]):\n",
    "    thermal_time = pair['timestamp'].strftime('%H:%M:%S.%f')[:-3]\n",
    "    rgb_idx = pair['rgb_frame_idx']\n",
    "    error = pair['rgb_error_ms']\n",
    "    \n",
    "    if i > 0:\n",
    "        time_diff = (pair['timestamp'] - pairs_final[i-1]['timestamp']).total_seconds() * 1000\n",
    "        rgb_diff = rgb_idx - pairs_final[i-1]['rgb_frame_idx']\n",
    "        print(f\"{i:2d}. {pair['pair_id']}: Thermal {thermal_time} â†’ RGB å¹€ {rgb_idx:5d} \"\n",
    "              f\"(èª¤å·® {error:4.1f}ms, æ™‚é–“é–“éš” {time_diff:6.1f}ms, RGBé–“éš” {rgb_diff} å¹€)\")\n",
    "    else:\n",
    "        print(f\"{i:2d}. {pair['pair_id']}: Thermal {thermal_time} â†’ RGB å¹€ {rgb_idx:5d} (èª¤å·® {error:4.1f}ms)\")\n",
    "\n",
    "# æª¢æŸ¥æ™‚é–“é–“éš”ä¸€è‡´æ€§\n",
    "time_intervals = []\n",
    "for i in range(len(pairs_final) - 1):\n",
    "    dt = (pairs_final[i+1]['timestamp'] - pairs_final[i]['timestamp']).total_seconds() * 1000\n",
    "    time_intervals.append(dt)\n",
    "\n",
    "print(f\"\\n\\næ™‚é–“é–“éš”ä¸€è‡´æ€§æª¢æŸ¥:\")\n",
    "print(f\"  å¹³å‡é–“éš”: {np.mean(time_intervals):.3f}ms\")\n",
    "print(f\"  æ¨™æº–å·®: {np.std(time_intervals):.3f}ms\")\n",
    "print(f\"  é æœŸå€¼: {FRAME_INTERVAL_MS:.3f}ms\")\n",
    "print(f\"  èª¤å·®: {abs(np.mean(time_intervals) - FRAME_INTERVAL_MS):.3f}ms\")\n",
    "\n",
    "if np.std(time_intervals) < 0.1:\n",
    "    print(f\"\\nâœ… æ™‚é–“é–“éš”éå¸¸ç©©å®šï¼ç´¯ç©èª¤å·®å•é¡Œå·²è§£æ±º\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ æ™‚é–“é–“éš”ä»æœ‰è®ŠåŒ–ï¼Œå¯èƒ½éœ€è¦é€²ä¸€æ­¥æª¢æŸ¥\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"\\nğŸ“ å¾ŒçºŒæ­¥é©Ÿ:\")\n",
    "print(f\"1. æª¢è¦–é©—è­‰å½±ç‰‡: {video_path}\")\n",
    "print(f\"2. æŸ¥çœ‹è¨ºæ–·åœ–: {DIAGNOSTIC_DIR / 'timing_diagnosis_v4.png'}\")\n",
    "print(f\"3. å¦‚æœåŒæ­¥è‰¯å¥½ï¼Œç¹¼çºŒé€²è¡Œ LabelMe æ¨™è¨»\")\n",
    "print(f\"4. å¦‚æœä»æœ‰å•é¡Œï¼Œæª¢æŸ¥ output.txt çš„ camera_start_time æ˜¯å¦æ­£ç¢º\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_thermal_rgb_motion(pairs: List[Dict], avi_path: Path, sample_size: int = 50):\n",
    "    \"\"\"\n",
    "    æ¯”å° Thermal å’Œ RGB çš„å‹•ä½œå…§å®¹ï¼Œçœ‹æ˜¯å¦æœ‰æ™‚é–“åç§»\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"æ¯”å° Thermal-RGB é‹å‹•å…§å®¹\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(avi_path))\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡\")\n",
    "        return\n",
    "    \n",
    "    # å‡å‹»å–æ¨£\n",
    "    step = len(pairs) // sample_size\n",
    "    sample_indices = range(0, len(pairs), max(1, step))[:sample_size]\n",
    "    \n",
    "    print(f\"\\nå–æ¨£ {len(list(sample_indices))} å°é€²è¡Œæ¯”å°...\")\n",
    "    \n",
    "    motion_correlations = []\n",
    "    \n",
    "    for pair_idx in sample_indices:\n",
    "        pair = pairs[pair_idx]\n",
    "        \n",
    "        # Thermal å‰å¾Œå¹€çš„å·®ç•°ï¼ˆé‹å‹•é‡ï¼‰\n",
    "        if pair_idx > 0 and pair_idx < len(pairs) - 1:\n",
    "            thermal_curr = pair['thermal']['image'].astype(float)\n",
    "            thermal_prev = pairs[pair_idx - 1]['thermal']['image'].astype(float)\n",
    "            thermal_next = pairs[pair_idx + 1]['thermal']['image'].astype(float)\n",
    "            \n",
    "            # é‹å‹•é‡ = ç›¸é„°å¹€çš„å¹³å‡å·®ç•°\n",
    "            thermal_motion = (np.mean(np.abs(thermal_curr - thermal_prev)) + \n",
    "                            np.mean(np.abs(thermal_next - thermal_curr))) / 2\n",
    "            \n",
    "            # RGB çš„ç›¸æ‡‰å¹€\n",
    "            rgb_curr_idx = pair['rgb_frame_idx']\n",
    "            \n",
    "            # è®€å– RGB å‰å¾Œå¹€\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, rgb_curr_idx - 1))\n",
    "            ret1, rgb_prev = cap.read()\n",
    "            \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, rgb_curr_idx)\n",
    "            ret2, rgb_curr = cap.read()\n",
    "            \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, min(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-1, rgb_curr_idx + 1))\n",
    "            ret3, rgb_next = cap.read()\n",
    "            \n",
    "            if ret1 and ret2 and ret3:\n",
    "                # è½‰ç°åº¦\n",
    "                rgb_prev_gray = cv2.cvtColor(rgb_prev, cv2.COLOR_BGR2GRAY).astype(float)\n",
    "                rgb_curr_gray = cv2.cvtColor(rgb_curr, cv2.COLOR_BGR2GRAY).astype(float)\n",
    "                rgb_next_gray = cv2.cvtColor(rgb_next, cv2.COLOR_BGR2GRAY).astype(float)\n",
    "                \n",
    "                rgb_motion = (np.mean(np.abs(rgb_curr_gray - rgb_prev_gray)) + \n",
    "                            np.mean(np.abs(rgb_next_gray - rgb_curr_gray))) / 2\n",
    "                \n",
    "                # å¦‚æœå…©é‚Šé‹å‹•é‡ç›¸é—œï¼Œèªªæ˜é…å°æ­£ç¢º\n",
    "                if rgb_motion > 0:\n",
    "                    correlation = thermal_motion / rgb_motion\n",
    "                    motion_correlations.append(correlation)\n",
    "    \n",
    "    if motion_correlations:\n",
    "        motion_correlations = np.array(motion_correlations)\n",
    "        \n",
    "        print(f\"\\nThermal-RGB é‹å‹•ç›¸é—œæ€§:\")\n",
    "        print(f\"  å¹³å‡æ¯”ç‡: {np.mean(motion_correlations):.4f}\")\n",
    "        print(f\"  æ¨™æº–å·®: {np.std(motion_correlations):.4f}\")\n",
    "        print(f\"  æœ€å°: {np.min(motion_correlations):.4f}\")\n",
    "        print(f\"  æœ€å¤§: {np.max(motion_correlations):.4f}\")\n",
    "        \n",
    "        # è¦–è¦ºåŒ–\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.hist(motion_correlations, bins=30, edgecolor='black', alpha=0.7, color='#4ecdc4')\n",
    "        plt.axvline(np.mean(motion_correlations), color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Mean: {np.mean(motion_correlations):.4f}')\n",
    "        plt.xlabel('Thermal-RGB Motion Ratio')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Motion Correlation Between Thermal and RGB')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = DIAGNOSTIC_DIR / 'motion_correlation.png'\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\nâœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# åŸ·è¡Œ\n",
    "compare_thermal_rgb_motion(pairs_adaptive, AVI_FILE, sample_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b35d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Thermal è¶…è§£æåº¦è¨“ç·´ï¼ˆPyTorchï¼‰\n",
      "======================================================================\n",
      "\n",
      "å®‰è£ä¾è³´å¥—ä»¶...\n",
      "âœ“ torch å·²å®‰è£\n",
      "âœ“ torchvision å·²å®‰è£\n",
      "å®‰è£ opencv-python...\n",
      "âœ“ numpy å·²å®‰è£\n",
      "å®‰è£ pillow...\n",
      "\n",
      "GPU æª¢æŸ¥:\n",
      "  è¨­å‚™: cuda:0\n",
      "  GPU åç¨±: NVIDIA GeForce RTX 2080 SUPER\n",
      "  CUDA ç‰ˆæœ¬: 12.8\n",
      "  âœ“ GPU å¯ç”¨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(f\"\\næº–å‚™è¨“ç·´è³‡æ–™...\")\\n\\noutput_base = LABELME_DIR.parent / \\'sr_models\\'\\noutput_base.mkdir(exist_ok=True)\\n\\nlr_dir, hr_dir = prepare_thermal_rgb_pairs(pairs_adaptive, ALIGNED_DIR, output_base)\\n\\nprint(f\"\\né–‹å§‹ä¸¦è¡Œè¨“ç·´è¶…è§£æåº¦æ¨¡å‹...\")\\nprint(f\"ä½¿ç”¨ GPU: {device}\")\\n\\nthreads = []\\n\\n# ç·šç¨‹ 1: ESPCN\\nt1 = threading.Thread(\\n    target=train_espcn,\\n    args=(lr_dir, hr_dir, output_base, device),\\n    daemon=False\\n)\\nthreads.append((\\'ESPCN\\', t1))\\n\\n# ç·šç¨‹ 2: SRResNet\\nt2 = threading.Thread(\\n    target=train_srresnet,\\n    args=(lr_dir, hr_dir, output_base, device),\\n    daemon=False\\n)\\nthreads.append((\\'SRResNet\\', t2))\\n\\n# å•Ÿå‹•\\nfor name, t in threads:\\n    print(f\"\\nğŸš€ å•Ÿå‹• {name} è¨“ç·´...\")\\n    t.start()\\n\\n# ç­‰å¾…å®Œæˆ\\nprint(f\"\\nâ³ ç­‰å¾…è¨“ç·´å®Œæˆ...\")\\nfor name, t in threads:\\n    t.join()\\n    print(f\"âœ“ {name} å®Œæˆ\")\\n\\nprint(f\"\\n{\\'=\\'*70}\")\\nprint(f\"âœ… è¶…è§£æåº¦æ¨¡å‹è¨“ç·´å®Œæˆï¼\")\\nprint(f\"{\\'=\\'*70}\")\\nprint(f\"\\næ¨¡å‹ä½ç½®:\")\\nprint(f\"  ESPCN: {output_base}/espcn_sr.pth\")\\nprint(f\"  SRResNet: {output_base}/srresnet_sr.pth\")\\nprint(f\"\\nç”¨é€”:\")\\nprint(f\"  - 32Ã—24 Thermal â†’ 256Ã—192 (8 å€è¶…è§£æåº¦)\")\\nprint(f\"  - ESPCN: å¿«é€Ÿã€è¼•é‡\")\\nprint(f\"  - SRResNet: é«˜ç²¾åº¦ã€ç´°ç¯€è±å¯Œ\")\\nprint(\"=\"*70)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 9: Thermal è¶…è§£æåº¦ï¼ˆPyTorch + 2080 Superï¼‰\n",
    "# ========================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Thermal è¶…è§£æåº¦è¨“ç·´ï¼ˆPyTorchï¼‰\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# å®‰è£ä¾è³´\n",
    "print(\"\\nå®‰è£ä¾è³´å¥—ä»¶...\")\n",
    "packages = ['torch', 'torchvision', 'opencv-python', 'numpy', 'pillow']\n",
    "\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "        print(f\"âœ“ {pkg} å·²å®‰è£\")\n",
    "    except ImportError:\n",
    "        print(f\"å®‰è£ {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nGPU æª¢æŸ¥:\")\n",
    "print(f\"  è¨­å‚™: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU åç¨±: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "    print(f\"  âœ“ GPU å¯ç”¨\")\n",
    "\n",
    "# ========================================\n",
    "# æº–å‚™é…å°çš„ Thermal å’Œ RGB è³‡æ–™\n",
    "# ========================================\n",
    "\n",
    "def prepare_thermal_rgb_pairs(pairs, aligned_dir, output_dir):\n",
    "    \"\"\"\n",
    "    å¾é…å°è³‡æ–™æº–å‚™è¨“ç·´é›†\n",
    "    Thermal 32Ã—24 â†’ RGB ç¸®å°åˆ° 32Ã—24ï¼Œä½œç‚ºç›®æ¨™\n",
    "    ç„¶å¾Œè¨“ç·´ 32Ã—24 â†’ 256Ã—192\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\næº–å‚™è¨“ç·´è³‡æ–™...\")\n",
    "    \n",
    "    # å»ºç«‹è³‡æ–™ç›®éŒ„\n",
    "    lr_dir = output_dir / 'lr_thermal'  # ä½è§£æåº¦ Thermalï¼ˆ32Ã—24ï¼Œè¼¸å…¥ï¼‰\n",
    "    hr_dir = output_dir / 'hr_thermal'  # é«˜è§£æåº¦ç›®æ¨™ï¼ˆ256Ã—192ï¼Œé æœŸè¼¸å‡ºï¼‰\n",
    "    \n",
    "    lr_dir.mkdir(parents=True, exist_ok=True)\n",
    "    hr_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(AVI_FILE))\n",
    "    \n",
    "    print(f\"  è™•ç† {min(2000, len(pairs))} å€‹é…å°...\")\n",
    "    \n",
    "    for idx, pair in enumerate(pairs[:min(2000, len(pairs))]):\n",
    "        # Thermal ä½è§£æåº¦ï¼ˆåŸå§‹ 32Ã—24ï¼‰\n",
    "        thermal_lr = pair['thermal']['image']\n",
    "        lr_path = lr_dir / f\"thermal_{idx:05d}.png\"\n",
    "        cv2.imwrite(str(lr_path), thermal_lr)\n",
    "        \n",
    "        # RGB ä½œç‚ºé«˜è§£æåº¦ç›®æ¨™\n",
    "        # ç­–ç•¥ï¼šRGB ç¸®å°åˆ° 256Ã—192ï¼ˆæ¥è¿‘ Thermal 32Ã—24 çš„ 8 å€ï¼‰\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, pair['rgb_frame_idx'])\n",
    "        ret, rgb_frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # RGB ç¸®å°åˆ° 256Ã—192ï¼ˆ8 å€ 32Ã—24ï¼‰\n",
    "            rgb_resized = cv2.resize(rgb_frame, (256, 192), interpolation=cv2.INTER_CUBIC)\n",
    "            # è½‰ç°éš\n",
    "            rgb_gray = cv2.cvtColor(rgb_resized, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            hr_path = hr_dir / f\"thermal_{idx:05d}.png\"\n",
    "            cv2.imwrite(str(hr_path), rgb_gray)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"  ä½è§£æåº¦ Thermalï¼ˆ32Ã—24ï¼‰: {len(list(lr_dir.glob('*.png')))} å¼µ\")\n",
    "    print(f\"  é«˜è§£æåº¦ç›®æ¨™ï¼ˆ256Ã—192ï¼‰: {len(list(hr_dir.glob('*.png')))} å¼µ\")\n",
    "    \n",
    "    return lr_dir, hr_dir\n",
    "\n",
    "# ========================================\n",
    "# å®šç¾©è¶…è§£æåº¦æ¨¡å‹ 1: ESPCNï¼ˆå¿«é€Ÿï¼‰\n",
    "# ========================================\n",
    "\n",
    "class ESPCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Sub-Pixel Convolutional Neural Network\n",
    "    32Ã—24 â†’ 256Ã—192ï¼ˆ8 å€ä¸Šæ¡æ¨£ï¼‰\n",
    "    \"\"\"\n",
    "    def __init__(self, upscale_factor=8):\n",
    "        super().__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1 * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, 24, 32)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        # output: (batch, 1, 192, 256)\n",
    "        return x\n",
    "\n",
    "# ========================================\n",
    "# å®šç¾©è¶…è§£æåº¦æ¨¡å‹ 2: SRResNetï¼ˆé«˜ç²¾åº¦ï¼‰\n",
    "# ========================================\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "class SRResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Super-Resolution ResNet\n",
    "    é«˜ç²¾åº¦ï¼Œé©åˆå°è³ªé‡è¦æ±‚é«˜çš„æ‡‰ç”¨\n",
    "    \"\"\"\n",
    "    def __init__(self, num_residual_blocks=16, upscale_factor=8):\n",
    "        super().__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        \n",
    "        # åˆå§‹å±¤\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, padding=4)\n",
    "        \n",
    "        # æ®˜å·®å¡Š\n",
    "        residual_blocks = [ResidualBlock(64) for _ in range(num_residual_blocks)]\n",
    "        self.residual_blocks = nn.Sequential(*residual_blocks)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # ä¸Šæ¡æ¨£å±¤\n",
    "        upsample_layers = []\n",
    "        for _ in range(int(np.log2(upscale_factor))):\n",
    "            upsample_layers.extend([\n",
    "                nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
    "                nn.PixelShuffle(2)\n",
    "            ])\n",
    "        self.upsample = nn.Sequential(*upsample_layers)\n",
    "        \n",
    "        # è¼¸å‡ºå±¤\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=9, padding=4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        residual = x\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.bn(self.conv2(x))\n",
    "        x = x + residual\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# ========================================\n",
    "# è‡ªè¨‚è³‡æ–™é›†\n",
    "# ========================================\n",
    "\n",
    "class ThermalRGBDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir):\n",
    "        self.lr_files = sorted(lr_dir.glob('*.png'))\n",
    "        self.hr_files = sorted(hr_dir.glob('*.png'))\n",
    "        \n",
    "        assert len(self.lr_files) == len(self.hr_files), f\"LR ({len(self.lr_files)}) å’Œ HR ({len(self.hr_files)}) æ•¸é‡ä¸ç¬¦\"\n",
    "        \n",
    "        print(f\"  è³‡æ–™é›†: {len(self.lr_files)} å°åœ–ç‰‡\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lr_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # è¼‰å…¥ä½è§£æåº¦ Thermalï¼ˆ32Ã—24ï¼‰\n",
    "        lr_img = cv2.imread(str(self.lr_files[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        if lr_img is None:\n",
    "            lr_img = np.zeros((24, 32), dtype=np.uint8)\n",
    "        lr_img = torch.FloatTensor(lr_img).unsqueeze(0) / 255.0  # (1, 24, 32)\n",
    "        \n",
    "        # è¼‰å…¥é«˜è§£æåº¦ç›®æ¨™ï¼ˆ256Ã—192ï¼Œä¾†è‡ª RGB ç¸®å°ç‰ˆï¼‰\n",
    "        hr_img = cv2.imread(str(self.hr_files[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        if hr_img is None:\n",
    "            hr_img = np.zeros((192, 256), dtype=np.uint8)\n",
    "        hr_img = torch.FloatTensor(hr_img).unsqueeze(0) / 255.0  # (1, 192, 256)\n",
    "        \n",
    "        return lr_img, hr_img\n",
    "\n",
    "# ========================================\n",
    "# è¨“ç·´å‡½å¼\n",
    "# ========================================\n",
    "\n",
    "def train_super_resolution(model_name, model, train_loader, device, epochs=50):\n",
    "    \"\"\"\n",
    "    è¨“ç·´è¶…è§£æåº¦æ¨¡å‹\n",
    "    \"\"\"\n",
    "    print(f\"\\nè¨“ç·´ {model_name}...\")\n",
    "    \n",
    "    criterion = nn.L1Loss()  # L1 Loss æ›´é©åˆ SR\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for lr_img, hr_img in train_loader:\n",
    "            lr_img = lr_img.to(device)\n",
    "            hr_img = hr_img.to(device)\n",
    "            \n",
    "            # å‰å‘å‚³æ’­\n",
    "            sr_img = model(lr_img)\n",
    "            \n",
    "            # è¨ˆç®—æå¤±\n",
    "            loss = criterion(sr_img, hr_img)\n",
    "            \n",
    "            # åå‘å‚³æ’­\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"  Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    print(f\"âœ… {model_name} è¨“ç·´å®Œæˆ\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ========================================\n",
    "# ä¸»ç¨‹å¼ï¼šä¸¦è¡Œè¨“ç·´å…©å€‹æ¨¡å‹\n",
    "# ========================================\n",
    "\n",
    "def train_espcn(lr_dir, hr_dir, output_dir, device):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ã€æ¨¡å‹ 1ã€‘ESPCN è¨“ç·´...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        dataset = ThermalRGBDataset(lr_dir, hr_dir)\n",
    "        train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "        \n",
    "        model = ESPCN(upscale_factor=8)\n",
    "        \n",
    "        model = train_super_resolution('ESPCN', model, train_loader, device, epochs=30)\n",
    "        \n",
    "        # ä¿å­˜æ¨¡å‹\n",
    "        model_path = output_dir / 'espcn_sr.pth'\n",
    "        torch.save(model.state_dict(), str(model_path))\n",
    "        print(f\"  æ¨¡å‹: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ESPCN è¨“ç·´å¤±æ•—: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def train_srresnet(lr_dir, hr_dir, output_dir, device):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ã€æ¨¡å‹ 2ã€‘SRResNet è¨“ç·´...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        dataset = ThermalRGBDataset(lr_dir, hr_dir)\n",
    "        train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "        \n",
    "        model = SRResNet(num_residual_blocks=16, upscale_factor=8)\n",
    "        \n",
    "        model = train_super_resolution('SRResNet', model, train_loader, device, epochs=50)\n",
    "        \n",
    "        # ä¿å­˜æ¨¡å‹\n",
    "        model_path = output_dir / 'srresnet_sr.pth'\n",
    "        torch.save(model.state_dict(), str(model_path))\n",
    "        print(f\"  æ¨¡å‹: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ SRResNet è¨“ç·´å¤±æ•—: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ========================================\n",
    "# åŸ·è¡Œ\n",
    "# ========================================\n",
    "\n",
    "\"\"\"print(f\"\\næº–å‚™è¨“ç·´è³‡æ–™...\")\n",
    "\n",
    "output_base = LABELME_DIR.parent / 'sr_models'\n",
    "output_base.mkdir(exist_ok=True)\n",
    "\n",
    "lr_dir, hr_dir = prepare_thermal_rgb_pairs(pairs_adaptive, ALIGNED_DIR, output_base)\n",
    "\n",
    "print(f\"\\né–‹å§‹ä¸¦è¡Œè¨“ç·´è¶…è§£æåº¦æ¨¡å‹...\")\n",
    "print(f\"ä½¿ç”¨ GPU: {device}\")\n",
    "\n",
    "threads = []\n",
    "\n",
    "# ç·šç¨‹ 1: ESPCN\n",
    "t1 = threading.Thread(\n",
    "    target=train_espcn,\n",
    "    args=(lr_dir, hr_dir, output_base, device),\n",
    "    daemon=False\n",
    ")\n",
    "threads.append(('ESPCN', t1))\n",
    "\n",
    "# ç·šç¨‹ 2: SRResNet\n",
    "t2 = threading.Thread(\n",
    "    target=train_srresnet,\n",
    "    args=(lr_dir, hr_dir, output_base, device),\n",
    "    daemon=False\n",
    ")\n",
    "threads.append(('SRResNet', t2))\n",
    "\n",
    "# å•Ÿå‹•\n",
    "for name, t in threads:\n",
    "    print(f\"\\nğŸš€ å•Ÿå‹• {name} è¨“ç·´...\")\n",
    "    t.start()\n",
    "\n",
    "# ç­‰å¾…å®Œæˆ\n",
    "print(f\"\\nâ³ ç­‰å¾…è¨“ç·´å®Œæˆ...\")\n",
    "for name, t in threads:\n",
    "    t.join()\n",
    "    print(f\"âœ“ {name} å®Œæˆ\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… è¶…è§£æåº¦æ¨¡å‹è¨“ç·´å®Œæˆï¼\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\næ¨¡å‹ä½ç½®:\")\n",
    "print(f\"  ESPCN: {output_base}/espcn_sr.pth\")\n",
    "print(f\"  SRResNet: {output_base}/srresnet_sr.pth\")\n",
    "print(f\"\\nç”¨é€”:\")\n",
    "print(f\"  - 32Ã—24 Thermal â†’ 256Ã—192 (8 å€è¶…è§£æåº¦)\")\n",
    "print(f\"  - ESPCN: å¿«é€Ÿã€è¼•é‡\")\n",
    "print(f\"  - SRResNet: é«˜ç²¾åº¦ã€ç´°ç¯€è±å¯Œ\")\n",
    "print(\"=\"*70)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "è¶…è§£æåº¦æ¨ç†å°ç…§ï¼ˆGPU åŠ é€Ÿï¼‰\n",
      "======================================================================\n",
      "\n",
      "æª¢æŸ¥ GPU ç‹€æ…‹:\n",
      "  è¨­å‚™: cuda:0\n",
      "  CUDA å¯ç”¨: True\n",
      "  GPU åç¨±: NVIDIA GeForce RTX 2080 SUPER\n",
      "  GPU è¨˜æ†¶é«”: 8.16 GB\n",
      "\n",
      "ç¸½åœ–ç‰‡æ•¸: 2000\n",
      "\n",
      "æ¨ç†ç¯„åœé¸é …:\n",
      "  æ–¹æ¡ˆ 1 (å‰ 10 å¼µ): [0:10]\n",
      "  æ–¹æ¡ˆ 2 (ä¸­é–“ 10 å¼µ): [100:110]\n",
      "  æ–¹æ¡ˆ 3 (å¾Œ 10 å¼µ): [1990:2000]\n",
      "\n",
      "è¼‰å…¥æ¨¡å‹...\n",
      "\n",
      "ã€æ¨ç†ã€‘ESPCN...\n",
      "\n",
      "æ¨ç† ESPCN...\n",
      "  ç¯„åœ: ç¬¬ 100 ~ 110 å¼µ\n",
      "  å–æ¨£é–“éš”: æ¯ 1 å¼µå– 1 å¼µ\n",
      "  å¯¦éš›ä½¿ç”¨: 10 å¼µåœ–ç‰‡\n",
      "  ç¸½åœ–ç‰‡æ•¸: 2000\n",
      "  [1/10] è™•ç†: thermal_00100.png (shape: (24, 32)) â†’ 0.34ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [2/10] è™•ç†: thermal_00101.png (shape: (24, 32)) â†’ 0.30ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [3/10] è™•ç†: thermal_00102.png (shape: (24, 32)) â†’ 0.27ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [4/10] è™•ç†: thermal_00103.png (shape: (24, 32)) â†’ 0.29ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [5/10] è™•ç†: thermal_00104.png (shape: (24, 32)) â†’ 0.33ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [6/10] è™•ç†: thermal_00105.png (shape: (24, 32)) â†’ 0.27ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [7/10] è™•ç†: thermal_00106.png (shape: (24, 32)) â†’ 0.26ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [8/10] è™•ç†: thermal_00107.png (shape: (24, 32)) â†’ 0.26ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [9/10] è™•ç†: thermal_00108.png (shape: (24, 32)) â†’ 0.28ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [10/10] è™•ç†: thermal_00109.png (shape: (24, 32)) â†’ 0.23ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "\n",
      "âœ… 10 å¼µåœ–ç‰‡æ¨ç†å®Œæˆï¼ˆåœ¨ GPU ä¸Šï¼‰\n",
      "\n",
      "æ¨ç†æ•ˆèƒ½çµ±è¨ˆ:\n",
      "  å¹³å‡æ¨ç†æ™‚é–“: 0.28ms\n",
      "  æœ€å°æ¨ç†æ™‚é–“: 0.23ms\n",
      "  æœ€å¤§æ¨ç†æ™‚é–“: 0.34ms\n",
      "\n",
      "âœ… å°ç…§åœ–å·²å„²å­˜: /home/gary/claude4.5/output_v7/sr_models/ESPCN_inference_[100-110].png\n",
      "\n",
      "\n",
      "ã€æ¨ç†ã€‘SRResNet...\n",
      "\n",
      "æ¨ç† SRResNet...\n",
      "  ç¯„åœ: ç¬¬ 100 ~ 110 å¼µ\n",
      "  å–æ¨£é–“éš”: æ¯ 1 å¼µå– 1 å¼µ\n",
      "  å¯¦éš›ä½¿ç”¨: 10 å¼µåœ–ç‰‡\n",
      "  ç¸½åœ–ç‰‡æ•¸: 2000\n",
      "  [1/10] è™•ç†: thermal_00100.png (shape: (24, 32)) â†’ 3.88ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [2/10] è™•ç†: thermal_00101.png (shape: (24, 32)) â†’ 3.37ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [3/10] è™•ç†: thermal_00102.png (shape: (24, 32)) â†’ 3.35ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [4/10] è™•ç†: thermal_00103.png (shape: (24, 32)) â†’ 3.36ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [5/10] è™•ç†: thermal_00104.png (shape: (24, 32)) â†’ 3.36ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [6/10] è™•ç†: thermal_00105.png (shape: (24, 32)) â†’ 3.34ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [7/10] è™•ç†: thermal_00106.png (shape: (24, 32)) â†’ 3.36ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [8/10] è™•ç†: thermal_00107.png (shape: (24, 32)) â†’ 3.35ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [9/10] è™•ç†: thermal_00108.png (shape: (24, 32)) â†’ 3.35ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "  [10/10] è™•ç†: thermal_00109.png (shape: (24, 32)) â†’ 3.35ms â†’ è¼¸å‡º shape: (192, 256)\n",
      "\n",
      "âœ… 10 å¼µåœ–ç‰‡æ¨ç†å®Œæˆï¼ˆåœ¨ GPU ä¸Šï¼‰\n",
      "\n",
      "æ¨ç†æ•ˆèƒ½çµ±è¨ˆ:\n",
      "  å¹³å‡æ¨ç†æ™‚é–“: 3.41ms\n",
      "  æœ€å°æ¨ç†æ™‚é–“: 3.34ms\n",
      "  æœ€å¤§æ¨ç†æ™‚é–“: 3.88ms\n",
      "\n",
      "âœ… å°ç…§åœ–å·²å„²å­˜: /home/gary/claude4.5/output_v7/sr_models/SRResNet_inference_[100-110].png\n",
      "\n",
      "======================================================================\n",
      "âœ… æ¨ç†å°ç…§å®Œæˆï¼ˆå·²ä½¿ç”¨ GPU åŠ é€Ÿï¼‰\n",
      "======================================================================\n",
      "\n",
      "å°ç…§åœ–ä½ç½®:\n",
      "  ESPCN: /home/gary/claude4.5/output_v7/sr_models/ESPCN_inference_[100-110].png\n",
      "  SRResNet: /home/gary/claude4.5/output_v7/sr_models/SRResNet_inference_[100-110].png\n",
      "\n",
      "å°ç…§åœ–èªªæ˜:\n",
      "  å·¦æ¬„: åŸå§‹ä½è§£æåº¦ Thermal (32Ã—24)\n",
      "  ä¸­æ¬„: æ¨¡å‹è¶…è§£æåº¦è¼¸å‡º (256Ã—192)\n",
      "  å³æ¬„: ç°¡å–®é›™ç·šæ€§æ’å€¼å°ç…§ (256Ã—192)\n",
      "\n",
      "è©•ä¼°é‡é»:\n",
      "  âœ“ æ¨¡å‹è¼¸å‡ºæ˜¯å¦æ¯”æ’å€¼ç‰ˆæœ¬æ›´æ¸…æ™°ç´°ç¯€è±å¯Œï¼Ÿ\n",
      "  âœ“ æ˜¯å¦ä¿ç•™äº† Thermal çš„é‚Šç•Œå’Œç‰¹å¾µï¼Ÿ\n",
      "  âœ“ æ˜¯å¦æœ‰éåº¦å¹³æ»‘æˆ–å½å½±ï¼Ÿ\n",
      "======================================================================\n",
      "\n",
      "âœ“ GPU è¨˜æ†¶é«”å·²æ¸…ç©º\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 10: è¶…è§£æåº¦æ¨ç†å°ç…§ï¼ˆGPU åŠ é€Ÿç‰ˆ + è‡ªè¨‚ç¯„åœï¼‰\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"è¶…è§£æåº¦æ¨ç†å°ç…§ï¼ˆGPU åŠ é€Ÿï¼‰\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def inference_and_visualize(model, lr_dir, output_dir, model_name, device, start_idx=100, end_idx=110, sample_every=1):\n",
    "    \"\"\"\n",
    "    ç”¨è¨“ç·´å¥½çš„æ¨¡å‹åšæ¨ç†ï¼Œç”Ÿæˆå°ç…§åœ–ï¼ˆGPU åŠ é€Ÿï¼‰\n",
    "    \n",
    "    åƒæ•¸:\n",
    "    - start_idx: é–‹å§‹ç´¢å¼•\n",
    "    - end_idx: çµæŸç´¢å¼•\n",
    "    - sample_every: æ¯ N å¼µå– 1 å¼µï¼ˆå¯åŠ é€Ÿï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\næ¨ç† {model_name}...\")\n",
    "    print(f\"  ç¯„åœ: ç¬¬ {start_idx} ~ {end_idx} å¼µ\")\n",
    "    print(f\"  å–æ¨£é–“éš”: æ¯ {sample_every} å¼µå– 1 å¼µ\")\n",
    "    \n",
    "    # å–æŒ‡å®šç¯„åœçš„åœ–ç‰‡\n",
    "    all_lr_files = sorted(lr_dir.glob('*.png'))\n",
    "    lr_files = all_lr_files[start_idx:end_idx:sample_every]\n",
    "    \n",
    "    print(f\"  å¯¦éš›ä½¿ç”¨: {len(lr_files)} å¼µåœ–ç‰‡\")\n",
    "    print(f\"  ç¸½åœ–ç‰‡æ•¸: {len(all_lr_files)}\")\n",
    "    \n",
    "    if not lr_files:\n",
    "        print(f\"âŒ æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    results = []\n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, lr_path in enumerate(lr_files):\n",
    "            # è¼‰å…¥ä½è§£æåº¦ Thermal\n",
    "            lr_img = cv2.imread(str(lr_path), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if lr_img is None:\n",
    "                print(f\"  âš ï¸ ç„¡æ³•è¼‰å…¥: {lr_path.name}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  [{idx+1}/{len(lr_files)}] è™•ç†: {lr_path.name} (shape: {lr_img.shape})\", end=\"\")\n",
    "            \n",
    "            # è½‰ç‚º tensorï¼Œä¸¦ç§»åˆ° GPU\n",
    "            lr_img_tensor = torch.FloatTensor(lr_img).unsqueeze(0).unsqueeze(0) / 255.0\n",
    "            lr_img_tensor = lr_img_tensor.to(device)\n",
    "            \n",
    "            # æ¨ç†è¨ˆæ™‚\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            with torch.cuda.device(device):\n",
    "                sr_img_tensor = model(lr_img_tensor)\n",
    "            \n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "            \n",
    "            print(f\" â†’ {inference_time*1000:.2f}ms\", end=\"\")\n",
    "            \n",
    "            # çµæœç§»å› CPU ä¸¦è½‰ç‚º numpy\n",
    "            sr_img = sr_img_tensor.squeeze().detach().cpu().numpy() * 255.0\n",
    "            sr_img = np.clip(sr_img, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            print(f\" â†’ è¼¸å‡º shape: {sr_img.shape}\")\n",
    "            \n",
    "            # ç°¡å–®çš„é›™ç·šæ€§æ’å€¼ä½œç‚ºå°ç…§\n",
    "            simple_upscale = cv2.resize(lr_img, (256, 192), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr_img,\n",
    "                'sr': sr_img,\n",
    "                'simple': simple_upscale,\n",
    "                'filename': lr_path.name\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nâœ… {len(results)} å¼µåœ–ç‰‡æ¨ç†å®Œæˆï¼ˆåœ¨ GPU ä¸Šï¼‰\")\n",
    "    print(f\"\\næ¨ç†æ•ˆèƒ½çµ±è¨ˆ:\")\n",
    "    print(f\"  å¹³å‡æ¨ç†æ™‚é–“: {np.mean(inference_times)*1000:.2f}ms\")\n",
    "    print(f\"  æœ€å°æ¨ç†æ™‚é–“: {np.min(inference_times)*1000:.2f}ms\")\n",
    "    print(f\"  æœ€å¤§æ¨ç†æ™‚é–“: {np.max(inference_times)*1000:.2f}ms\")\n",
    "    \n",
    "    # ç”Ÿæˆå°ç…§åœ–\n",
    "    num_samples = len(results)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        # ä½è§£æåº¦ï¼ˆ32Ã—24ï¼‰\n",
    "        axes[idx, 0].imshow(result['lr'], cmap='hot')\n",
    "        axes[idx, 0].set_title(f'Low Res (32Ã—24)\\n{result[\"filename\"]}', fontsize=9)\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # æ¨¡å‹è¼¸å‡ºï¼ˆ256Ã—192ï¼‰\n",
    "        axes[idx, 1].imshow(result['sr'], cmap='hot')\n",
    "        axes[idx, 1].set_title(f'{model_name}\\n(256Ã—192)', fontsize=9)\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        # ç°¡å–®æ’å€¼å°ç…§ï¼ˆ256Ã—192ï¼‰\n",
    "        axes[idx, 2].imshow(result['simple'], cmap='hot')\n",
    "        axes[idx, 2].set_title('Simple Upscale\\n(256Ã—192)', fontsize=9)\n",
    "        axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path = output_base / f'{model_name}_inference_[{start_idx}-{end_idx}].png'\n",
    "    plt.savefig(str(output_path), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nâœ… å°ç…§åœ–å·²å„²å­˜: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# ========================================\n",
    "# è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹ä¸¦æ¨ç†\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\næª¢æŸ¥ GPU ç‹€æ…‹:\")\n",
    "print(f\"  è¨­å‚™: {device}\")\n",
    "print(f\"  CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU åç¨±: {torch.cuda.get_device_name(device)}\")\n",
    "    print(f\"  GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(device).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "output_base = LABELME_DIR.parent / 'sr_models'\n",
    "lr_dir = output_base / 'lr_thermal'\n",
    "\n",
    "# æª¢æŸ¥ç¸½åœ–ç‰‡æ•¸\n",
    "total_images = len(list(lr_dir.glob('*.png')))\n",
    "print(f\"\\nç¸½åœ–ç‰‡æ•¸: {total_images}\")\n",
    "\n",
    "# ========================================\n",
    "# è‡ªè¨‚åƒæ•¸å€åŸŸï¼ˆä½ å¯ä»¥æ”¹é€™è£¡ï¼‰\n",
    "# ========================================\n",
    "\n",
    "# æ–¹æ¡ˆ 1: çœ‹å‰ 10 å¼µ\n",
    "START_IDX_1 = 0\n",
    "END_IDX_1 = 10\n",
    "\n",
    "# æ–¹æ¡ˆ 2: çœ‹ä¸­é–“ 10 å¼µ\n",
    "START_IDX_2 = 100\n",
    "END_IDX_2 = 110\n",
    "\n",
    "# æ–¹æ¡ˆ 3: çœ‹å¾Œé¢ 10 å¼µ\n",
    "START_IDX_3 = total_images - 10\n",
    "END_IDX_3 = total_images\n",
    "\n",
    "print(f\"\\næ¨ç†ç¯„åœé¸é …:\")\n",
    "print(f\"  æ–¹æ¡ˆ 1 (å‰ 10 å¼µ): [{START_IDX_1}:{END_IDX_1}]\")\n",
    "print(f\"  æ–¹æ¡ˆ 2 (ä¸­é–“ 10 å¼µ): [{START_IDX_2}:{END_IDX_2}]\")\n",
    "print(f\"  æ–¹æ¡ˆ 3 (å¾Œ 10 å¼µ): [{START_IDX_3}:{END_IDX_3}]\")\n",
    "\n",
    "print(f\"\\nè¼‰å…¥æ¨¡å‹...\")\n",
    "\n",
    "# ESPCN æ¨ç†\n",
    "espcn_path = output_base / 'espcn_sr.pth'\n",
    "if espcn_path.exists():\n",
    "    print(f\"\\nã€æ¨ç†ã€‘ESPCN...\")\n",
    "    espcn_model = ESPCN(upscale_factor=8)\n",
    "    espcn_model.load_state_dict(torch.load(str(espcn_path), map_location=device))\n",
    "    espcn_model.to(device)\n",
    "    \n",
    "    # æ¨ç†æ–¹æ¡ˆ 2ï¼ˆå¯æ”¹æˆ 1 æˆ– 3ï¼‰\n",
    "    espcn_output = inference_and_visualize(\n",
    "        espcn_model, lr_dir, output_base, 'ESPCN', device,\n",
    "        start_idx=START_IDX_2,\n",
    "        end_idx=END_IDX_2,\n",
    "        sample_every=1\n",
    "    )\n",
    "else:\n",
    "    print(f\"âŒ ESPCN æ¨¡å‹ä¸å­˜åœ¨: {espcn_path}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# SRResNet æ¨ç†\n",
    "srresnet_path = output_base / 'srresnet_sr.pth'\n",
    "if srresnet_path.exists():\n",
    "    print(f\"\\nã€æ¨ç†ã€‘SRResNet...\")\n",
    "    srresnet_model = SRResNet(num_residual_blocks=16, upscale_factor=8)\n",
    "    srresnet_model.load_state_dict(torch.load(str(srresnet_path), map_location=device))\n",
    "    srresnet_model.to(device)\n",
    "    \n",
    "    # æ¨ç†æ–¹æ¡ˆ 2ï¼ˆå¯æ”¹æˆ 1 æˆ– 3ï¼‰\n",
    "    srresnet_output = inference_and_visualize(\n",
    "        srresnet_model, lr_dir, output_base, 'SRResNet', device,\n",
    "        start_idx=START_IDX_2,\n",
    "        end_idx=END_IDX_2,\n",
    "        sample_every=1\n",
    "    )\n",
    "else:\n",
    "    print(f\"âŒ SRResNet æ¨¡å‹ä¸å­˜åœ¨: {srresnet_path}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… æ¨ç†å°ç…§å®Œæˆï¼ˆå·²ä½¿ç”¨ GPU åŠ é€Ÿï¼‰\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nå°ç…§åœ–ä½ç½®:\")\n",
    "print(f\"  ESPCN: {output_base}/ESPCN_inference_[{START_IDX_2}-{END_IDX_2}].png\")\n",
    "print(f\"  SRResNet: {output_base}/SRResNet_inference_[{START_IDX_2}-{END_IDX_2}].png\")\n",
    "print(f\"\\nå°ç…§åœ–èªªæ˜:\")\n",
    "print(f\"  å·¦æ¬„: åŸå§‹ä½è§£æåº¦ Thermal (32Ã—24)\")\n",
    "print(f\"  ä¸­æ¬„: æ¨¡å‹è¶…è§£æåº¦è¼¸å‡º (256Ã—192)\")\n",
    "print(f\"  å³æ¬„: ç°¡å–®é›™ç·šæ€§æ’å€¼å°ç…§ (256Ã—192)\")\n",
    "print(f\"\\nè©•ä¼°é‡é»:\")\n",
    "print(f\"  âœ“ æ¨¡å‹è¼¸å‡ºæ˜¯å¦æ¯”æ’å€¼ç‰ˆæœ¬æ›´æ¸…æ™°ç´°ç¯€è±å¯Œï¼Ÿ\")\n",
    "print(f\"  âœ“ æ˜¯å¦ä¿ç•™äº† Thermal çš„é‚Šç•Œå’Œç‰¹å¾µï¼Ÿ\")\n",
    "print(f\"  âœ“ æ˜¯å¦æœ‰éåº¦å¹³æ»‘æˆ–å½å½±ï¼Ÿ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# æ¸…ç©º GPU è¨˜æ†¶é«”\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"\\nâœ“ GPU è¨˜æ†¶é«”å·²æ¸…ç©º\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
